{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb35ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from Levenshtein import ratio as levenshtein_ratio_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6bde68",
   "metadata": {},
   "source": [
    "**CODING EXERCISE ANALYSIS NOTEBOOK**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39754b8a",
   "metadata": {},
   "source": [
    "I/O Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec184e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"data/consistency_analysis.csv\"\n",
    "OUTPUT_DIR = \"figures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7dc169",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985d23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(df):\n",
    "    \"\"\"Performs exploratory data analysis.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for EDA\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\nShape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "\n",
    "    print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "\n",
    "    print(f\"\\nUnique contracts: {df['Contract'].nunique()}\")\n",
    "    print(f\"Unique coders: {df['Coder'].unique().tolist()}\")\n",
    "    print(f\"Rounds: {df['Round'].unique().tolist()}\")\n",
    "    print(f\"Difficulty levels: {df['Difficulty'].unique().tolist()}\")\n",
    "\n",
    "    print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "\n",
    "    print(f\"\\nFirst 10 rows:\\n{df.head(10).to_string()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fccd85",
   "metadata": {},
   "source": [
    "Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34378a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Clean data.\n",
    "\n",
    "    - Remove trailing whitespace on string columns\n",
    "    - Extract prefix column\n",
    "    - Populate binary variables\n",
    "    - Create combined lookup key\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for cleaning\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: cleaned copy of dataframe\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"Contract\"] = df[\"Contract\"].str.strip()\n",
    "    df[\"Service_Raw\"] = df[\"Service_Raw\"].str.strip()\n",
    "\n",
    "    df[\"prefix\"] = df[\"NAICS_Raw\"].astype(str).str[:2]\n",
    "    df[\"prefix\"] = df[\"prefix\"].replace(\"na\", np.nan)\n",
    "\n",
    "    df[\"has_naics\"] = df[\"NAICS_Raw\"].notna() & (df[\"NAICS_Raw\"] != \"\")\n",
    "\n",
    "    df[\"is_multicode\"] = df[\"NAICS_Raw\"].str.contains(\";\", na=False)\n",
    "\n",
    "    df[\"lookup_key\"] = df[\"Contract\"] + \"|\" + df[\"Service_Raw\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c61818a",
   "metadata": {},
   "source": [
    "**SERVICE CLUSTERING**\n",
    "\n",
    "PURPOSE: Identify when coders used different names for the same service.\n",
    "E.g., \"Mechanic\", \"Lead Mechanic\", \"Mechanic II\" may be the same role.\n",
    "\n",
    "Use string similarity to cluster similar service names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73fa3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_EQUIVALENCES = {\n",
    "    \"Equipment operator\": [\n",
    "        \"Equipment operator\",\n",
    "        \"Heavy equipment operator\",\n",
    "        \"Motor equipment operator\",\n",
    "        \"Senior heavy equipment operator\",\n",
    "    ],\n",
    "    \"Mechanic\": [\n",
    "        \"Mechanic\",\n",
    "        \"Mechanic II\",\n",
    "    ],\n",
    "    \"Groundskeeper\": [\n",
    "        \"Groundskeeper\",\n",
    "        \"Groundskeeping\",\n",
    "    ],\n",
    "    \"Fire protection\": [\n",
    "        \"Fire protection\",\n",
    "        \"Fire prevention\",\n",
    "    ],\n",
    "    \"Sewage treatment\": [\n",
    "        \"Sewage treatment\",\n",
    "        \"Sewage related\",\n",
    "    ],\n",
    "    \"Road maintenance\": [\n",
    "        \"Road maintenance\",\n",
    "        \"Highway and road maintenance\",\n",
    "        \"Road related\",\n",
    "    ],\n",
    "    \"Traffic control\": [\n",
    "        \"Traffic control crew\",\n",
    "        \"Traffic maintenance\",\n",
    "        \"Traffic and vegetation control\",\n",
    "        \"Traffic and vegetation control mechanic\",\n",
    "    ],\n",
    "    \"Truck driver\": [\n",
    "        \"Truck driver\",\n",
    "        \"Truck driver apprentice\",\n",
    "    ],\n",
    "    \"Building maintenance\": [\n",
    "        \"Building maintenance\",\n",
    "        \"Building and grounds maintenance\",\n",
    "    ],\n",
    "    \"Parks maintenance\": [\n",
    "        \"Park maintenance\",\n",
    "        \"Parks and landscaping\",\n",
    "    ],\n",
    "    \"Sewer maintenance\": [\n",
    "        \"Sewer maintenance\",\n",
    "        \"Sewer repair\",\n",
    "        \"Sewer line maintenance\",\n",
    "    ],\n",
    "    \"Recreation\": [\n",
    "        \"Recreation\",\n",
    "        \"Recreation programs\",\n",
    "        \"Recreation and lifeguards\",\n",
    "    ],\n",
    "    \"Engineering\": [\n",
    "        \"Engineering\",\n",
    "        \"Engineering \",  # trailing space variant in case not picked up by cleaning\n",
    "    ],\n",
    "    \"Surveying\": [\n",
    "        \"Surveying\",\n",
    "        \"Land surveyor\",\n",
    "        \"County surveyor\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5839bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_normalization_map(equivalences):\n",
    "    \"\"\"Build mapping from variant names to canonical names.\n",
    "\n",
    "    Args:\n",
    "        equivalences (dict): mapping of variant names to canonical names; sourced once by Levenshtein then hard-coded\n",
    "\n",
    "    Returns:\n",
    "        dict: map of normalizations\n",
    "    \"\"\"\n",
    "    norm_map = {}\n",
    "    for canonical, variants in equivalences.items():\n",
    "        for variant in variants:\n",
    "            norm_map[variant.lower().strip()] = canonical\n",
    "    return norm_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef1a25",
   "metadata": {},
   "source": [
    "Apply service normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec352cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_service_names(df, equivalences=SERVICE_EQUIVALENCES):\n",
    "    \"\"\"Apply service name normalization to dataframe. Creates 'Service_Normalized' column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for service normalization\n",
    "        equivalences (dict, optional): mapping of canonical --> equivalent names. Defaults to SERVICE_EQUIVALENCES.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: same matrix with 'Service_Normalized' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    norm_map = build_normalization_map(equivalences)\n",
    "\n",
    "    def normalize(service_name):\n",
    "        if pd.isna(service_name):\n",
    "            return service_name\n",
    "        key = service_name.lower().strip()\n",
    "        return norm_map.get(key, service_name)\n",
    "\n",
    "    df[\"Service_Normalized\"] = df[\"Service_Raw\"].apply(normalize)\n",
    "\n",
    "    # Report normalization impact\n",
    "    raw_unique = df[\"Service_Raw\"].nunique()\n",
    "    norm_unique = df[\"Service_Normalized\"].nunique()\n",
    "    merged = raw_unique - norm_unique\n",
    "\n",
    "    print(f\"Service name normalization complete.\")\n",
    "    print(f\"  Unique services (raw): {raw_unique}\")\n",
    "    print(f\"  Unique services (normalized): {norm_unique}\")\n",
    "    print(f\"  Services merged: {merged}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "772e43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_preparation(df):\n",
    "    \"\"\"Run validation checks on prepared data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for checks\n",
    "\n",
    "    Returns:\n",
    "        bool: all checks passed or not\n",
    "    \"\"\"\n",
    "    checks = []\n",
    "\n",
    "    # Check 1: Service_Normalized exists\n",
    "    checks.append(\n",
    "        (\"Service_Normalized column exists\", \"Service_Normalized\" in df.columns)\n",
    "    )\n",
    "\n",
    "    # Check 2: No null contracts\n",
    "    checks.append((\"No null Contract IDs\", df[\"Contract\"].notna().all()))\n",
    "\n",
    "    # Check 3: Normalization reduced unique count\n",
    "    raw = df[\"Service_Raw\"].nunique()\n",
    "    norm = df[\"Service_Normalized\"].nunique()\n",
    "    checks.append((f\"Normalization merged services ({raw} → {norm})\", norm < raw))\n",
    "\n",
    "    # Check 4: Expected columns present\n",
    "    expected = [\n",
    "        \"Contract\",\n",
    "        \"Difficulty\",\n",
    "        \"Service_Raw\",\n",
    "        \"Service_Normalized\",\n",
    "        \"Coder\",\n",
    "        \"Round\",\n",
    "        \"NAICS_Raw\",\n",
    "        \"prefix\",\n",
    "    ]\n",
    "    checks.append(\n",
    "        (\"All expected columns present\", all(c in df.columns for c in expected))\n",
    "    )\n",
    "\n",
    "    print(\"\\nData Preparation Validation:\")\n",
    "    print(\"-\" * 50)\n",
    "    for check_name, passed in checks:\n",
    "        status = \"✓ PASS\" if passed else \"✗ FAIL\"\n",
    "        print(f\"  {status}: {check_name}\")\n",
    "\n",
    "    all_passed = all(passed for _, passed in checks)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"  {'All checks passed!' if all_passed else 'SOME CHECKS FAILED'}\")\n",
    "\n",
    "    return all_passed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a274258",
   "metadata": {},
   "source": [
    "**DESCRIPTIVE ANALYSIS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38889e",
   "metadata": {},
   "source": [
    "Coder Behavior Profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33082f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_coder_profiles(df):\n",
    "    \"\"\"Analyze how each coder uses different NAICS code families.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, List] A tuple containing\n",
    "            - pivot: pivot table prefix use by coder\n",
    "            - top_prefixes: top 5 prefixes across all coders\n",
    "    \"\"\"\n",
    "    # Count prefix usage by coder\n",
    "    prefix_counts = (\n",
    "        df[df[\"prefix\"].notna()]\n",
    "        .groupby([\"Coder\", \"prefix\"])\n",
    "        .size()\n",
    "        .rename(\"n\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Calculate percentages\n",
    "    prefix_counts[\"pct\"] = (\n",
    "        prefix_counts[\"n\"] / prefix_counts.groupby(\"Coder\")[\"n\"].transform(\"sum\") * 100\n",
    "    )\n",
    "\n",
    "    # Pivot for comparison\n",
    "    pivot = prefix_counts.pivot(index=\"Coder\", columns=\"prefix\", values=\"pct\").fillna(0)\n",
    "\n",
    "    # Get top 5 prefixes overall\n",
    "    top_prefixes = (\n",
    "        prefix_counts.groupby(\"prefix\")[\"n\"]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(5)\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    print(\"\\nCoder Prefix Usage (% of each coder's assignments):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(pivot[top_prefixes].round(1).to_string())\n",
    "\n",
    "    return pivot, top_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09550ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_coder_tendencies(pivot, top_prefixes):\n",
    "    \"\"\"Identify systematic coder tendencies based on deviation from mean.\n",
    "\n",
    "    Args:\n",
    "        pivot (pd.DataFrame): pivot table prefix use by coder\n",
    "        top_prefixes (List): top 5 prefixes across all coders\n",
    "    \"\"\"\n",
    "    print(\"\\nCoder Tendencies (deviation from group mean):\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for prefix in top_prefixes:\n",
    "        col = pivot[prefix]\n",
    "        mean = col.mean()\n",
    "        for coder in col.index:\n",
    "            val = col[coder]\n",
    "            diff = val - mean\n",
    "            if abs(diff) > 5:  # More than 5pp deviation\n",
    "                direction = \"favors\" if diff > 0 else \"underuses\"\n",
    "                print(\n",
    "                    f\"  {coder} {direction} {prefix}xxx: {val:.1f}% vs {mean:.1f}% mean ({diff:+.1f}pp)\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821706ee",
   "metadata": {},
   "source": [
    "Identification Overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "945449c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_identification_overlap(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"\n",
    "    Analyze how often coders identify the same services.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (String, optional): name of services column. Defaults to 'Service_Normalized'.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.DataFrame] Tuple of two dataframes containing\n",
    "            - overlap_stats: Dict with overlap statistics by round\n",
    "            - service_coder_counts: DataFrame with coder counts per service\n",
    "    \"\"\"\n",
    "    # Count coders per service per contract\n",
    "    service_coders = (\n",
    "        df.groupby([\"Contract\", \"Round\", service_col])[\"Coder\"]\n",
    "        .apply(lambda x: set(x))\n",
    "        .reset_index()\n",
    "    )\n",
    "    service_coders[\"num_coders\"] = service_coders[\"Coder\"].apply(len)\n",
    "\n",
    "    # Compute overlap statistics by round\n",
    "    overlap_stats = {}\n",
    "    for round_num in df[\"Round\"].unique():\n",
    "        round_data = service_coders[service_coders[\"Round\"] == round_num]\n",
    "        total = len(round_data)\n",
    "\n",
    "        all_three = (round_data[\"num_coders\"] == 3).sum()\n",
    "        two_coders = (round_data[\"num_coders\"] == 2).sum()\n",
    "        one_coder = (round_data[\"num_coders\"] == 1).sum()\n",
    "\n",
    "        overlap_stats[round_num] = {\n",
    "            \"total_services\": total,\n",
    "            \"all_3_coders\": all_three,\n",
    "            \"all_3_pct\": all_three / total * 100 if total > 0 else 0,\n",
    "            \"2_coders\": two_coders,\n",
    "            \"2_coders_pct\": two_coders / total * 100 if total > 0 else 0,\n",
    "            \"1_coder\": one_coder,\n",
    "            \"1_coder_pct\": one_coder / total * 100 if total > 0 else 0,\n",
    "        }\n",
    "\n",
    "    print(\"\\nIdentification Overlap by Round:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Metric':<30} {'Round 1':>12} {'Round 2':>12}\")\n",
    "    print(\"-\" * 60)\n",
    "    for metric in [\"all_3_pct\", \"2_coders_pct\", \"1_coder_pct\"]:\n",
    "        label = metric.replace(\"_pct\", \"\").replace(\"_\", \" \").title()\n",
    "        r1 = overlap_stats.get(1, {}).get(metric, 0)\n",
    "        r2 = overlap_stats.get(2, {}).get(metric, 0)\n",
    "        print(f\"{label:<30} {r1:>11.1f}% {r2:>11.1f}%\")\n",
    "\n",
    "    return overlap_stats, service_coders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ae1d0",
   "metadata": {},
   "source": [
    "**CORE METRICS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e1c84",
   "metadata": {},
   "source": [
    "Bootstrap CIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e097cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(data, statistic=np.mean, n_bootstrap=1000, ci=0.95):\n",
    "    \"\"\"\n",
    "    Calculate bootstrap confidence interval for a statistic.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): matrix for analysis\n",
    "        statistic (func, optional): function to compute. Defaults to np.mean.\n",
    "        n_bootstrap (int, optional): number of bootstrap samples. Defaults to 1000.\n",
    "        ci (float): confidence level. Defaults to 0.95\n",
    "\n",
    "    Returns:\n",
    "        tuple[float, float, float] tuple containing\n",
    "            - point_estimate: float returned value from provided function\n",
    "            - lower_bound: float lower bound from provided function and CI\n",
    "            - upper_bound: float upper bound from provided function and CI\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    n = len(data)\n",
    "\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "    point_estimate = statistic(data)\n",
    "\n",
    "    # Bootstrap resampling\n",
    "    bootstrap_stats = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        bootstrap_stats.append(statistic(sample))\n",
    "\n",
    "    alpha = 1 - ci\n",
    "    lower = np.percentile(bootstrap_stats, alpha / 2 * 100)\n",
    "    upper = np.percentile(bootstrap_stats, (1 - alpha / 2) * 100)\n",
    "\n",
    "    return (point_estimate, lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789033e3",
   "metadata": {},
   "source": [
    "Classification Agreement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23ff94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapping_services(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"\n",
    "    Get services identified by 2+ coders within each contract.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (String, Optional): name of service column in df. Defaults to 'Service_Normalized'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: matrix of shared services per contract\n",
    "        with columns Contract, Service, Coders (list), NAICS_Codes (list), num_coders\n",
    "\n",
    "    \"\"\"\n",
    "    service_groups = (\n",
    "        df.groupby([\"Contract\", \"Round\", \"Difficulty\", service_col])\n",
    "        .agg({\"Coder\": list, \"NAICS_Raw\": list})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    service_groups[\"num_coders\"] = service_groups[\"Coder\"].apply(len)\n",
    "    overlaps = service_groups[service_groups[\"num_coders\"] >= 2].copy()\n",
    "\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bb5a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_agreement(naics_list):\n",
    "    \"\"\"\n",
    "    Check if all NAICS codes in list are identical.\n",
    "\n",
    "    Args:\n",
    "        naics_list (List): list of NAICS codes from one contract\n",
    "\n",
    "    Returns:\n",
    "        bool: agree, disagree, or insufficient data (None)\n",
    "    \"\"\"\n",
    "    codes = [str(c).strip() for c in naics_list if pd.notna(c) and str(c).strip()]\n",
    "    if len(codes) < 2:\n",
    "        return None\n",
    "    return len(set(codes)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2606b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_agreement_rate(df, service_col=\"Service_Normalized\", with_ci=True):\n",
    "    \"\"\"Compute classification agreement rate for overlapping services.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (str, optional): name of service column from df. Defaults to \"Service_Normalized\".\n",
    "        with_ci (bool, optional): include confidence interval. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        dict: agreement_rate, ci_lower, ci_upper, n (number of overlapping services), agreements (count of agreements)\n",
    "    \"\"\"\n",
    "    overlaps = get_overlapping_services(df, service_col)\n",
    "\n",
    "    if len(overlaps) == 0:\n",
    "        return None\n",
    "\n",
    "    # Check agreement for each overlap\n",
    "    overlaps[\"agreed\"] = overlaps[\"NAICS_Raw\"].apply(check_agreement)\n",
    "\n",
    "    # Filter to valid comparisons\n",
    "    valid = overlaps[overlaps[\"agreed\"].notna()]\n",
    "\n",
    "    if len(valid) == 0:\n",
    "        return None\n",
    "\n",
    "    # Compute agreement\n",
    "    agreements = valid[\"agreed\"].astype(int).tolist()\n",
    "    n = len(agreements)\n",
    "    agree_count = sum(agreements)\n",
    "\n",
    "    if with_ci:\n",
    "        point, lower, upper = bootstrap_ci(agreements)\n",
    "    else:\n",
    "        point = np.mean(agreements)\n",
    "        lower, upper = np.nan, np.nan\n",
    "\n",
    "    return {\n",
    "        \"agreement_rate\": point,\n",
    "        \"ci_lower\": lower,\n",
    "        \"ci_upper\": upper,\n",
    "        \"n\": n,\n",
    "        \"agreements\": agree_count,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d93a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_agreement_matrix(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"Compute agreement rates by Round and Difficulty.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (str, optional): name of service column from df. Defaults to \"Service_Normalized\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: matrix with agreement metrics for each segment\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Overall\n",
    "    overall = compute_agreement_rate(df, service_col)\n",
    "    if overall:\n",
    "        results.append({\"Segment\": \"Overall\", **overall})\n",
    "\n",
    "    # By Round\n",
    "    for round_num in sorted(df[\"Round\"].unique()):\n",
    "        df_round = df[df[\"Round\"] == round_num]\n",
    "        rate = compute_agreement_rate(df_round, service_col)\n",
    "        if rate:\n",
    "            results.append({\"Segment\": f\"Round {round_num}\", **rate})\n",
    "\n",
    "    # By Difficulty\n",
    "    for diff in [\"Easy\", \"Medium\", \"Hard\"]:\n",
    "        df_diff = df[df[\"Difficulty\"] == diff]\n",
    "        rate = compute_agreement_rate(df_diff, service_col)\n",
    "        if rate:\n",
    "            results.append({\"Segment\": diff, **rate})\n",
    "\n",
    "    # By Round × Difficulty\n",
    "    for round_num in sorted(df[\"Round\"].unique()):\n",
    "        for diff in [\"Easy\", \"Medium\", \"Hard\"]:\n",
    "            df_subset = df[(df[\"Round\"] == round_num) & (df[\"Difficulty\"] == diff)]\n",
    "            rate = compute_agreement_rate(df_subset, service_col)\n",
    "            if rate:\n",
    "                results.append({\"Segment\": f\"R{round_num} {diff}\", **rate})\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a55e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_agreement_table(results_df):\n",
    "    \"\"\"Pretty print agreement results\n",
    "\n",
    "    Args:\n",
    "        results_df (pd.DataFrame): results from compute_agreement_matrix()\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nClassification Agreement (Normalized Service Names, 95% CI):\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Segment':<15} {'Agreement':>12} {'95% CI':>20} {'n':>8}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for _, row in results_df.iterrows():\n",
    "        rate = row[\"agreement_rate\"] * 100\n",
    "        ci_low = row[\"ci_lower\"] * 100\n",
    "        ci_high = row[\"ci_upper\"] * 100\n",
    "        ci_str = f\"[{ci_low:.1f}%, {ci_high:.1f}%]\"\n",
    "        print(f\"{row['Segment']:<15} {rate:>11.1f}% {ci_str:>20} {row['n']:>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceadba9",
   "metadata": {},
   "source": [
    "Pairwise Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12055c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_agreement(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"Compute agreement rates for each coder pair.\n",
    "\n",
    "    Returns DataFrame with pairwise agreement statistics.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (str, optional): name of service column from df. Defaults to \"Service_Normalized\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: pairwise agreement matrix\n",
    "    \"\"\"\n",
    "\n",
    "    overlaps = get_overlapping_services(df, service_col)\n",
    "\n",
    "    # For each overlap, get coder-code pairs\n",
    "    pair_agreements = defaultdict(list)\n",
    "\n",
    "    for _, row in overlaps.iterrows():\n",
    "        coders = row[\"Coder\"]\n",
    "        codes = row[\"NAICS_Raw\"]\n",
    "\n",
    "        # Build coder -> code mapping\n",
    "        coder_codes = dict(zip(coders, codes))\n",
    "\n",
    "        # Check each pair\n",
    "        for c1, c2 in combinations(sorted(coder_codes.keys()), 2):\n",
    "            code1 = str(coder_codes[c1]).strip() if pd.notna(coder_codes[c1]) else \"\"\n",
    "            code2 = str(coder_codes[c2]).strip() if pd.notna(coder_codes[c2]) else \"\"\n",
    "\n",
    "            if code1 and code2:\n",
    "                agreed = code1 == code2\n",
    "                pair_agreements[(c1, c2)].append(1 if agreed else 0)\n",
    "\n",
    "    # Compute statistics\n",
    "    results = []\n",
    "    for pair, agreements in pair_agreements.items():\n",
    "        point, lower, upper = bootstrap_ci(agreements)\n",
    "        results.append(\n",
    "            {\n",
    "                \"Coder_Pair\": f\"{pair[0]}-{pair[1]}\",\n",
    "                \"agreement_rate\": point,\n",
    "                \"ci_lower\": lower,\n",
    "                \"ci_upper\": upper,\n",
    "                \"n\": len(agreements),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "421705ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_similarity(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"Compute Jaccard similarity of code sets between coders for each contract.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (str, optional): name of service column from df. Defaults to \"Service_Normalized\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: matrix with Jaccard metrics per contract\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for contract in df[\"Contract\"].unique():\n",
    "        df_contract = df[df[\"Contract\"] == contract]\n",
    "        difficulty = df_contract[\"Difficulty\"].iloc[0]\n",
    "        round_num = df_contract[\"Round\"].iloc[0]\n",
    "\n",
    "        # Get code sets by coder\n",
    "        coder_codes = {}\n",
    "        for coder in df_contract[\"Coder\"].unique():\n",
    "            coder_df = df_contract[df_contract[\"Coder\"] == coder]\n",
    "            codes = set()\n",
    "            for naics in coder_df[\"NAICS_Raw\"].dropna():\n",
    "                # Handle multi-codes\n",
    "                for code in str(naics).split(\";\"):\n",
    "                    code = code.strip()\n",
    "                    if code:\n",
    "                        codes.add(code)\n",
    "            coder_codes[coder] = codes\n",
    "\n",
    "        # Compute pairwise Jaccard\n",
    "        jaccard_scores = []\n",
    "        pairs = []\n",
    "        for c1, c2 in combinations(sorted(coder_codes.keys()), 2):\n",
    "            set1, set2 = coder_codes[c1], coder_codes[c2]\n",
    "            if set1 or set2:  # At least one non-empty\n",
    "                intersection = len(set1 & set2)\n",
    "                union = len(set1 | set2)\n",
    "                jaccard = intersection / union if union > 0 else 0\n",
    "                jaccard_scores.append(jaccard)\n",
    "                pairs.append((c1, c2, jaccard))\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"Contract\": contract,\n",
    "                \"Difficulty\": difficulty,\n",
    "                \"Round\": round_num,\n",
    "                \"mean_jaccard\": np.mean(jaccard_scores) if jaccard_scores else np.nan,\n",
    "                \"min_jaccard\": np.min(jaccard_scores) if jaccard_scores else np.nan,\n",
    "                \"pairs\": pairs,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa8e98",
   "metadata": {},
   "source": [
    "**DIAGNOSTIC ANALYSIS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca957aff",
   "metadata": {},
   "source": [
    "Taxonomy of Disagreements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeb2b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_disagreements(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"Extract all disagreements with details for categorization.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (str, optional): name of service column from df. Defaults to \"Service_Normalized\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: disagreements matrix\n",
    "    \"\"\"\n",
    "    overlaps = get_overlapping_services(df, service_col)\n",
    "    overlaps[\"agreed\"] = overlaps[\"NAICS_Raw\"].apply(check_agreement)\n",
    "\n",
    "    disagreements = overlaps[overlaps[\"agreed\"] == False].copy()\n",
    "\n",
    "    # Add analysis columns\n",
    "    def get_prefixes(codes):\n",
    "        prefixes = set()\n",
    "        for c in codes:\n",
    "            if pd.notna(c):\n",
    "                code_str = str(c).split(\";\")[0][:2]\n",
    "                if code_str and code_str != \"na\":\n",
    "                    prefixes.add(code_str)\n",
    "        return prefixes\n",
    "\n",
    "    disagreements[\"prefixes\"] = disagreements[\"NAICS_Raw\"].apply(get_prefixes)\n",
    "    disagreements[\"same_prefix\"] = disagreements[\"prefixes\"].apply(\n",
    "        lambda x: len(x) == 1\n",
    "    )\n",
    "    disagreements[\"unique_codes\"] = disagreements[\"NAICS_Raw\"].apply(\n",
    "        lambda x: sorted(set(str(c) for c in x if pd.notna(c)))\n",
    "    )\n",
    "\n",
    "    return disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "323b75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_disagreement(row):\n",
    "    \"\"\"Categorize a disagreement by type.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): disagreement row\n",
    "\n",
    "    Returns:\n",
    "        str: category of disagreement for given row\n",
    "    \"\"\"\n",
    "    if row[\"same_prefix\"]:\n",
    "        return \"Granularity (same prefix)\"\n",
    "\n",
    "    prefixes = row[\"prefixes\"]\n",
    "\n",
    "    # Check for common confusion patterns\n",
    "    if {\"23\", \"56\"} & prefixes and len(prefixes) == 2:\n",
    "        return \"Construction vs Admin (23/56)\"\n",
    "    if {\"22\", \"23\"} & prefixes and len(prefixes) == 2:\n",
    "        return \"Utilities vs Construction (22/23)\"\n",
    "    if {\"54\", \"92\"} & prefixes:\n",
    "        return \"Professional vs Public Admin (54/92)\"\n",
    "\n",
    "    return \"Other substantive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6743b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_disagreement_taxonomy(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"Categorize all disagreements and compute distribution.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (str, optional): name of service column from df. Defaults to \"Service_Normalized\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: summary statistics on disagreement types\n",
    "    \"\"\"\n",
    "    disagreements = extract_disagreements(df, service_col)\n",
    "\n",
    "    if len(disagreements) == 0:\n",
    "        print(\"No disagreements found!\")\n",
    "        return None\n",
    "\n",
    "    disagreements[\"category\"] = disagreements.apply(categorize_disagreement, axis=1)\n",
    "\n",
    "    # Compute distribution\n",
    "    category_counts = disagreements[\"category\"].value_counts()\n",
    "    category_pcts = (category_counts / len(disagreements) * 100).round(1)\n",
    "\n",
    "    print(\"\\nDisagreement Taxonomy:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Total disagreements: {len(disagreements)}\")\n",
    "    print()\n",
    "    for cat, count in category_counts.items():\n",
    "        pct = category_pcts[cat]\n",
    "        print(f\"  {cat:<35} {count:>3} ({pct:>5.1f}%)\")\n",
    "\n",
    "    # Compute addressable percentage\n",
    "    granularity = category_counts.get(\"Granularity (same prefix)\", 0)\n",
    "    addressable = (\n",
    "        len(disagreements) - granularity\n",
    "    )  # All non-granularity are \"addressable\"\n",
    "    addressable_pct = (len(disagreements) - granularity) / len(disagreements) * 100\n",
    "\n",
    "    print()\n",
    "    print(\n",
    "        f\"  Granularity (low impact): {granularity} ({granularity/len(disagreements)*100:.1f}%)\"\n",
    "    )\n",
    "    print(f\"  Substantive (addressable): {addressable} ({addressable_pct:.1f}%)\")\n",
    "\n",
    "    return disagreements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7aa834",
   "metadata": {},
   "source": [
    "Prefix Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1330c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"Build matrix showing which NAICS prefixes are confused with each other.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (str, optional): name of service column from df. Defaults to \"Service_Normalized\".\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, dict] tuple containing\n",
    "            - matrix: confusion matrix\n",
    "            - confusion_counts: values for matrix\n",
    "    \"\"\"\n",
    "    disagreements = extract_disagreements(df, service_col)\n",
    "\n",
    "    confusion_counts = defaultdict(int)\n",
    "\n",
    "    for _, row in disagreements.iterrows():\n",
    "        prefixes = sorted(row[\"prefixes\"])\n",
    "        for p1, p2 in combinations(prefixes, 2):\n",
    "            confusion_counts[(p1, p2)] += 1\n",
    "\n",
    "    # Build matrix\n",
    "    all_prefixes = sorted(set(p for pair in confusion_counts.keys() for p in pair))\n",
    "    matrix = pd.DataFrame(0, index=all_prefixes, columns=all_prefixes)\n",
    "\n",
    "    for (p1, p2), count in confusion_counts.items():\n",
    "        matrix.loc[p1, p2] = count\n",
    "        matrix.loc[p2, p1] = count\n",
    "\n",
    "    return matrix, confusion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e40dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_pairs(confusion_counts, top_n=10):\n",
    "    \"\"\"Print top confused prefix pairs.\n",
    "\n",
    "    Args:\n",
    "        confusion_counts (dict): values returned from build_confusion_matrix()\n",
    "        top_n (int, optional): top x prefixes. Defaults to 10.\n",
    "    \"\"\"\n",
    "    PREFIX_NAMES = {\n",
    "        \"22\": \"Utilities\",\n",
    "        \"23\": \"Construction\",\n",
    "        \"48\": \"Transportation\",\n",
    "        \"54\": \"Professional\",\n",
    "        \"56\": \"Admin/Support\",\n",
    "        \"71\": \"Recreation\",\n",
    "        \"81\": \"Repair/Maint\",\n",
    "        \"92\": \"Public Admin\",\n",
    "    }\n",
    "\n",
    "    print(\"\\nTop Confused Prefix Pairs:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    sorted_pairs = sorted(confusion_counts.items(), key=lambda x: -x[1])[:top_n]\n",
    "    for (p1, p2), count in sorted_pairs:\n",
    "        name1 = PREFIX_NAMES.get(p1, \"?\")\n",
    "        name2 = PREFIX_NAMES.get(p2, \"?\")\n",
    "        print(f\"  {p1} ({name1}) ↔ {p2} ({name2}): {count} disagreements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2db69f",
   "metadata": {},
   "source": [
    "Cross-Contract Consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87270921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cross_contract_consistency(df, service_col=\"Service_Normalized\"):\n",
    "    \"\"\"Check if the same service gets the same code across different contracts.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "        service_col (str, optional): name of service column from df. Defaults to \"Service_Normalized\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: analysis results\n",
    "    \"\"\"\n",
    "    # Group by normalized service name across ALL contracts\n",
    "    service_codes = (\n",
    "        df.groupby(service_col)\n",
    "        .agg(\n",
    "            {\n",
    "                \"NAICS_Raw\": lambda x: [c for c in x.dropna().unique()],\n",
    "                \"Contract\": lambda x: list(x.unique()),\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    service_codes[\"num_contracts\"] = service_codes[\"Contract\"].apply(len)\n",
    "\n",
    "    # Only analyze services in 2+ contracts\n",
    "    multi_contract = service_codes[service_codes[\"num_contracts\"] >= 2].copy()\n",
    "\n",
    "    # Check consistency\n",
    "    def get_unique_primary_codes(codes):\n",
    "        \"\"\"Get unique primary codes (first code if multi-code).\"\"\"\n",
    "        primary = set()\n",
    "        for c in codes:\n",
    "            if pd.notna(c):\n",
    "                primary.add(str(c).split(\";\")[0])\n",
    "        return sorted(primary)\n",
    "\n",
    "    multi_contract[\"unique_codes\"] = multi_contract[\"NAICS_Raw\"].apply(\n",
    "        get_unique_primary_codes\n",
    "    )\n",
    "    multi_contract[\"num_codes\"] = multi_contract[\"unique_codes\"].apply(len)\n",
    "    multi_contract[\"is_consistent\"] = multi_contract[\"num_codes\"] == 1\n",
    "\n",
    "    # Report\n",
    "    consistent = multi_contract[\"is_consistent\"].sum()\n",
    "    total = len(multi_contract)\n",
    "\n",
    "    print(\"\\nCross-Contract Consistency:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Services appearing in 2+ contracts: {total}\")\n",
    "    print(f\"Consistently coded: {consistent} ({consistent/total*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"Inconsistently coded: {total - consistent} ({(total-consistent)/total*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Show inconsistent services\n",
    "    inconsistent = multi_contract[~multi_contract[\"is_consistent\"]].sort_values(\n",
    "        \"num_codes\", ascending=False\n",
    "    )\n",
    "\n",
    "    if len(inconsistent) > 0:\n",
    "        print(\"\\nInconsistent Services (need handbook guidance):\")\n",
    "        for _, row in inconsistent.head(10).iterrows():\n",
    "            print(f\"  {row[service_col]:<35} → {row['unique_codes']}\")\n",
    "\n",
    "    return multi_contract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1e357",
   "metadata": {},
   "source": [
    "**QUERY IMPACT SIMULATION**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6cf1b9",
   "metadata": {},
   "source": [
    "Define Query Scenarios Here\n",
    "|Query Name|Queried Codes and Prefixes|\n",
    "|---|---|\n",
    "|road_maintenance|237310, 237|\n",
    "|Add a query name here|And add the codes/prefixes the researcher would search for here|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf4529",
   "metadata": {},
   "source": [
    "Query utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6742217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_SCENARIOS = {\n",
    "    # =========================================================================\n",
    "    # CONSTRUCTION & INFRASTRUCTURE (23xxx) - 97 occurrences in data\n",
    "    # =========================================================================\n",
    "    \"highway_construction\": [\"237310\"],\n",
    "    \"commercial_building\": [\"236220\", \"236\"],\n",
    "    \"utility_line_construction\": [\"237110\", \"237130\"],\n",
    "    \"specialty_trades\": [\n",
    "        \"238210\",\n",
    "        \"238220\",\n",
    "        \"238350\",\n",
    "    ],  # Electrical, plumbing, finishing\n",
    "    \"infrastructure_general\": [\"237\"],  # Broad prefix search\n",
    "    # =========================================================================\n",
    "    # PUBLIC ADMINISTRATION (92xxx) - 75 occurrences in data\n",
    "    # =========================================================================\n",
    "    \"courts_legal\": [\"922110\", \"922130\"],  # Courts, legal counsel (13 hits)\n",
    "    \"public_safety_general\": [\"922\"],  # Broad safety search\n",
    "    \"environmental_regulation\": [\n",
    "        \"924120\",\n",
    "        \"925120\",\n",
    "    ],  # Conservation, urban dev (12 hits)\n",
    "    \"executive_offices\": [\"921130\", \"921110\"],  # Executive/legislative\n",
    "    \"justice_system\": [\"922110\", \"922140\", \"922150\"],  # Courts, corrections, parole\n",
    "    \"public_order\": [\"922190\"],  # Other public order\n",
    "    \"tax_assessment\": [\"921130\"],  # Tax assessor services\n",
    "    # =========================================================================\n",
    "    # ADMINISTRATIVE & SUPPORT (56xxx) - 41 occurrences in data\n",
    "    # =========================================================================\n",
    "    \"facilities_support\": [\"561210\", \"561211\"],  # 16+ hits\n",
    "    \"landscaping_services\": [\"561730\"],  # 9 hits\n",
    "    \"security_services\": [\"561612\", \"561710\"],  # Security guards, patrol\n",
    "    \"waste_management\": [\"562111\", \"562920\"],  # Waste collection, remediation\n",
    "    \"office_support\": [\"561110\"],  # Office admin\n",
    "    \"janitorial\": [\"561720\"],  # Custodial services\n",
    "    # =========================================================================\n",
    "    # UTILITIES (22xxx) - 14 occurrences in data\n",
    "    # =========================================================================\n",
    "    \"water_supply\": [\"221310\"],  # 4 hits\n",
    "    \"sewage_treatment\": [\"221320\"],  # 10 hits\n",
    "    \"utilities_general\": [\"221\"],  # Broad prefix\n",
    "    # =========================================================================\n",
    "    # PROFESSIONAL SERVICES (54xxx) - 21 occurrences in data\n",
    "    # =========================================================================\n",
    "    \"engineering_services\": [\"541330\", \"541320\"],  # Civil engineering (6 hits)\n",
    "    \"surveying_mapping\": [\"541370\"],  # Surveying (6 hits)\n",
    "    \"it_services\": [\"541512\", \"541513\", \"541519\"],  # Computer services\n",
    "    \"inspection_services\": [\"541350\"],  # Building inspection (4 hits)\n",
    "    # =========================================================================\n",
    "    # RECREATION (71xxx) - 9 occurrences in data\n",
    "    # =========================================================================\n",
    "    \"fitness_recreation\": [\"713940\", \"713910\"],  # Fitness, golf (5+ hits)\n",
    "    \"nature_parks\": [\"712190\"],  # Nature parks (3 hits)\n",
    "    \"recreation_general\": [\"71\"],  # Broad prefix\n",
    "    # =========================================================================\n",
    "    # REPAIR & MAINTENANCE (81xxx) - 11 occurrences in data\n",
    "    # =========================================================================\n",
    "    \"auto_repair\": [\"811111\", \"811310\"],  # Auto repair (7 hits)\n",
    "    \"equipment_repair\": [\"811310\"],  # Commercial equipment\n",
    "    \"personal_services\": [\"812220\", \"812910\"],  # Cemeteries, pet care\n",
    "    \"repair_general\": [\"81\"],  # Broad prefix\n",
    "    # =========================================================================\n",
    "    # TRANSPORTATION (48xxx) - 4 occurrences in data\n",
    "    # =========================================================================\n",
    "    \"towing_services\": [\"488410\"],  # Towing (2 hits)\n",
    "    \"traffic_services\": [\"488490\"],  # Traffic management (2 hits)\n",
    "    \"transportation_support\": [\"488\"],  # Broad prefix\n",
    "}\n",
    "\n",
    "QUERY_CATEGORIES = {\n",
    "    \"Construction\": [\n",
    "        \"highway_construction\",\n",
    "        \"commercial_building\",\n",
    "        \"utility_line_construction\",\n",
    "        \"specialty_trades\",\n",
    "        \"infrastructure_general\",\n",
    "    ],\n",
    "    \"Public Admin\": [\n",
    "        \"courts_legal\",\n",
    "        \"public_safety_general\",\n",
    "        \"environmental_regulation\",\n",
    "        \"executive_offices\",\n",
    "        \"justice_system\",\n",
    "        \"public_order\",\n",
    "        \"tax_assessment\",\n",
    "    ],\n",
    "    \"Support Services\": [\n",
    "        \"facilities_support\",\n",
    "        \"landscaping_services\",\n",
    "        \"security_services\",\n",
    "        \"waste_management\",\n",
    "        \"office_support\",\n",
    "        \"janitorial\",\n",
    "    ],\n",
    "    \"Utilities\": [\"water_supply\", \"sewage_treatment\", \"utilities_general\"],\n",
    "    \"Professional\": [\n",
    "        \"engineering_services\",\n",
    "        \"surveying_mapping\",\n",
    "        \"it_services\",\n",
    "        \"inspection_services\",\n",
    "    ],\n",
    "    \"Recreation\": [\"fitness_recreation\", \"nature_parks\", \"recreation_general\"],\n",
    "    \"Repair\": [\"auto_repair\", \"personal_services\", \"repair_general\"],\n",
    "    \"Transportation\": [\"towing_services\", \"traffic_services\", \"transportation_general\"],\n",
    "}\n",
    "\n",
    "\n",
    "QUERY_TO_CATEGORY = {}\n",
    "for cat, queries in QUERY_CATEGORIES.items():\n",
    "    for q in queries:\n",
    "        QUERY_TO_CATEGORY[q] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50276367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codes_set(naics_str):\n",
    "    \"\"\"Parse NAICS codes from semicolon-delimited string.\n",
    "\n",
    "    Args:\n",
    "        naics_str (str): value of NAICS column for given row\n",
    "\n",
    "    Returns:\n",
    "        set[str]: list of unique codes parsed from string\n",
    "    \"\"\"\n",
    "    if pd.isna(naics_str) or naics_str == \"\":\n",
    "        return set()\n",
    "    codes = set()\n",
    "    for code in str(naics_str).split(\";\"):\n",
    "        code = code.strip()\n",
    "        if code and code != \"nan\":\n",
    "            codes.add(code)\n",
    "    return codes\n",
    "\n",
    "\n",
    "def query_matches(code_set, query_codes):\n",
    "    \"\"\"Check if code set satisfies query (exact or prefix match).\n",
    "\n",
    "    Args:\n",
    "        code_set (set[str]): set of unique codes from get_codes_set()\n",
    "        query_codes (list[str]): set of codes from query sim from QUERY_CODES\n",
    "\n",
    "    Returns:\n",
    "        bool: code set satisfies query?\n",
    "    \"\"\"\n",
    "    for code in code_set:\n",
    "        code_str = str(code).strip()\n",
    "        for query in query_codes:\n",
    "            query_str = str(query).strip()\n",
    "            if code_str == query_str or code_str.startswith(query_str):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def bootstrap_ci(values, n_bootstrap=1000, ci=0.95):\n",
    "    \"\"\"Compute bootstrap confidence interval.\n",
    "\n",
    "    Args:\n",
    "        values (arraylike[int]): values for bootstrapping\n",
    "        n_bootstrap (int, optional): number of resamples. Defaults to 1000\n",
    "        ci (float): threshold for confidence interval. Defaults to 0.95\n",
    "\n",
    "    Returns:\n",
    "        tuple[int, int, int] tuple containing\n",
    "            - point: mean value\n",
    "            - upper: upper bound for given ci\n",
    "            - lower: lower bound for given ci\n",
    "    \"\"\"\n",
    "    if len(values) == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    values = np.array(values)\n",
    "    point = np.mean(values)\n",
    "\n",
    "    boot_means = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(values, size=len(values), replace=True)\n",
    "        boot_means.append(np.mean(sample))\n",
    "\n",
    "    alpha = 1 - ci\n",
    "    lower = np.percentile(boot_means, alpha / 2 * 100)\n",
    "    upper = np.percentile(boot_means, (1 - alpha / 2) * 100)\n",
    "\n",
    "    return point, lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05f9e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(df):\n",
    "    \"\"\"Run full query simulation.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): matrix for analysis\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: simulation results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for contract in df[\"Contract\"].unique():\n",
    "        df_contract = df[df[\"Contract\"] == contract]\n",
    "        difficulty = df_contract[\"Difficulty\"].iloc[0]\n",
    "        round_num = df_contract[\"Round\"].iloc[0]\n",
    "\n",
    "        # Build code sets for each coder\n",
    "        codes_by_coder = {}\n",
    "        for coder in df_contract[\"Coder\"].unique():\n",
    "            coder_df = df_contract[df_contract[\"Coder\"] == coder]\n",
    "            codes = set()\n",
    "            for naics in coder_df[\"NAICS_Raw\"].dropna():\n",
    "                codes.update(get_codes_set(naics))\n",
    "            codes_by_coder[coder] = codes\n",
    "\n",
    "        # Union of all coders\n",
    "        union_codes = set.union(*codes_by_coder.values()) if codes_by_coder else set()\n",
    "\n",
    "        # Test each query\n",
    "        for query_name, query_codes in QUERY_SCENARIOS.items():\n",
    "            union_hit = query_matches(union_codes, query_codes)\n",
    "\n",
    "            row = {\n",
    "                \"contract\": contract,\n",
    "                \"difficulty\": difficulty,\n",
    "                \"round\": round_num,\n",
    "                \"query\": query_name,\n",
    "                \"category\": QUERY_TO_CATEGORY.get(query_name, \"Unknown\"),\n",
    "                \"union_hit\": int(union_hit),\n",
    "            }\n",
    "\n",
    "            for coder, codes in codes_by_coder.items():\n",
    "                coder_hit = query_matches(codes, query_codes)\n",
    "                row[f\"{coder}_hit\"] = int(coder_hit)\n",
    "                row[f\"{coder}_miss\"] = int(union_hit and not coder_hit)\n",
    "\n",
    "            results.append(row)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d2308e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_overall(sim_df, coder_cols):\n",
    "    \"\"\"Summary statistics for simulation results.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): results from run_simulation()\n",
    "        coder_cols (list[str]): list of column names\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: summary statistics from simulation\n",
    "    \"\"\"\n",
    "    union_hits = sim_df[\"union_hit\"].sum()\n",
    "    total_queries = len(sim_df)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"OVERALL SIMULATION STATISTICS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nTotal queries tested: {len(QUERY_SCENARIOS)}\")\n",
    "    print(f\"Total contracts: {sim_df['contract'].nunique()}\")\n",
    "    print(f\"Query-contract combinations: {total_queries}\")\n",
    "    print(f\"Union hits (queries findable by at least one coder): {union_hits}\")\n",
    "    print(f\"Union hit rate: {union_hits/total_queries*100:.1f}%\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"Per-Coder Performance:\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    coder_stats = []\n",
    "    for col in sorted(coder_cols):\n",
    "        coder = col.replace(\"_hit\", \"\")\n",
    "        hits = sim_df[col].sum()\n",
    "        misses = sim_df[f\"{coder}_miss\"].sum()\n",
    "        miss_rate = misses / union_hits * 100 if union_hits > 0 else 0\n",
    "\n",
    "        # Bootstrap CI on miss rate\n",
    "        miss_indicators = sim_df[sim_df[\"union_hit\"] == 1][f\"{coder}_miss\"].values\n",
    "        point, lower, upper = bootstrap_ci(miss_indicators)\n",
    "\n",
    "        print(\n",
    "            f\"  {coder}: {hits} hits, {misses} misses, \"\n",
    "            f\"miss rate = {miss_rate:.1f}% [{lower*100:.1f}%, {upper*100:.1f}%]\"\n",
    "        )\n",
    "\n",
    "        coder_stats.append(\n",
    "            {\n",
    "                \"coder\": coder,\n",
    "                \"hits\": hits,\n",
    "                \"misses\": misses,\n",
    "                \"miss_rate\": miss_rate,\n",
    "                \"ci_lower\": lower * 100,\n",
    "                \"ci_upper\": upper * 100,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Average miss rate\n",
    "    avg_miss = np.mean([s[\"miss_rate\"] for s in coder_stats])\n",
    "    print(f\"\\n  Average single-coder miss rate: {avg_miss:.1f}%\")\n",
    "\n",
    "    return pd.DataFrame(coder_stats)\n",
    "\n",
    "\n",
    "def analyze_by_category(sim_df, coder_cols):\n",
    "    \"\"\"Analyze miss rates by query category.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): simulation results from run_simulation()\n",
    "        coder_cols (list[str]): list of column names\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: by-category miss rates matrix\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"MISS RATES BY QUERY CATEGORY\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for category in QUERY_CATEGORIES.keys():\n",
    "        cat_df = sim_df[sim_df[\"category\"] == category]\n",
    "        cat_union = cat_df[\"union_hit\"].sum()\n",
    "\n",
    "        if cat_union == 0:\n",
    "            continue\n",
    "\n",
    "        cat_result = {\n",
    "            \"category\": category,\n",
    "            \"n_queries\": len(QUERY_CATEGORIES[category]),\n",
    "            \"union_hits\": cat_union,\n",
    "        }\n",
    "\n",
    "        miss_rates = []\n",
    "        for col in coder_cols:\n",
    "            coder = col.replace(\"_hit\", \"\")\n",
    "            coder_misses = cat_df[f\"{coder}_miss\"].sum()\n",
    "            miss_rate = coder_misses / cat_union * 100\n",
    "            cat_result[f\"{coder}_miss_rate\"] = miss_rate\n",
    "            miss_rates.append(miss_rate)\n",
    "\n",
    "        cat_result[\"avg_miss_rate\"] = np.mean(miss_rates)\n",
    "        cat_result[\"max_miss_rate\"] = np.max(miss_rates)\n",
    "        cat_result[\"min_miss_rate\"] = np.min(miss_rates)\n",
    "        cat_result[\"miss_rate_range\"] = np.max(miss_rates) - np.min(miss_rates)\n",
    "\n",
    "        # Bootstrap CI on average miss rate\n",
    "        miss_indicators = []\n",
    "        for col in coder_cols:\n",
    "            coder = col.replace(\"_hit\", \"\")\n",
    "            miss_indicators.extend(\n",
    "                cat_df[cat_df[\"union_hit\"] == 1][f\"{coder}_miss\"].values\n",
    "            )\n",
    "\n",
    "        if len(miss_indicators) > 0:\n",
    "            point, lower, upper = bootstrap_ci(miss_indicators)\n",
    "            cat_result[\"ci_lower\"] = lower * 100\n",
    "            cat_result[\"ci_upper\"] = upper * 100\n",
    "\n",
    "        results.append(cat_result)\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"avg_miss_rate\", ascending=False)\n",
    "\n",
    "    print(\n",
    "        f\"\\n{'Category':<18} {'Hits':>6} {'Avg Miss':>10} {'95% CI':>18} {'Range':>10}\"\n",
    "    )\n",
    "    print(\"-\" * 65)\n",
    "    for _, row in results_df.iterrows():\n",
    "        ci_str = f\"[{row.get('ci_lower', 0):.1f}%, {row.get('ci_upper', 0):.1f}%]\"\n",
    "        print(\n",
    "            f\"{row['category']:<18} {row['union_hits']:>6} {row['avg_miss_rate']:>9.1f}% \"\n",
    "            f\"{ci_str:>18} {row['miss_rate_range']:>9.1f}pp\"\n",
    "        )\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def analyze_by_difficulty(sim_df, coder_cols):\n",
    "    \"\"\"Analyze miss rates by contract difficulty.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): simulation results from run_simulation()\n",
    "        coder_cols (list[str]): list of column names\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: by-difficulty miss rates matrix\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"MISS RATES BY DIFFICULTY\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for diff in [\"Easy\", \"Medium\", \"Hard\"]:\n",
    "        diff_df = sim_df[sim_df[\"difficulty\"] == diff]\n",
    "        diff_union = diff_df[\"union_hit\"].sum()\n",
    "\n",
    "        if diff_union == 0:\n",
    "            continue\n",
    "\n",
    "        diff_result = {\n",
    "            \"difficulty\": diff,\n",
    "            \"n_contracts\": diff_df[\"contract\"].nunique(),\n",
    "            \"union_hits\": diff_union,\n",
    "        }\n",
    "\n",
    "        miss_rates = []\n",
    "        for col in coder_cols:\n",
    "            coder = col.replace(\"_hit\", \"\")\n",
    "            coder_misses = diff_df[f\"{coder}_miss\"].sum()\n",
    "            miss_rate = coder_misses / diff_union * 100\n",
    "            diff_result[f\"{coder}_miss_rate\"] = miss_rate\n",
    "            miss_rates.append(miss_rate)\n",
    "\n",
    "        diff_result[\"avg_miss_rate\"] = np.mean(miss_rates)\n",
    "\n",
    "        # Bootstrap CI\n",
    "        miss_indicators = []\n",
    "        for col in coder_cols:\n",
    "            coder = col.replace(\"_hit\", \"\")\n",
    "            miss_indicators.extend(\n",
    "                diff_df[diff_df[\"union_hit\"] == 1][f\"{coder}_miss\"].values\n",
    "            )\n",
    "\n",
    "        if len(miss_indicators) > 0:\n",
    "            point, lower, upper = bootstrap_ci(miss_indicators)\n",
    "            diff_result[\"ci_lower\"] = lower * 100\n",
    "            diff_result[\"ci_upper\"] = upper * 100\n",
    "\n",
    "        results.append(diff_result)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    print(\n",
    "        f\"\\n{'Difficulty':<10} {'Contracts':>10} {'Hits':>8} {'Avg Miss':>10} {'95% CI':>20}\"\n",
    "    )\n",
    "    print(\"-\" * 60)\n",
    "    for _, row in results_df.iterrows():\n",
    "        ci_str = f\"[{row.get('ci_lower', 0):.1f}%, {row.get('ci_upper', 0):.1f}%]\"\n",
    "        print(\n",
    "            f\"{row['difficulty']:<10} {row['n_contracts']:>10} {row['union_hits']:>8} \"\n",
    "            f\"{row['avg_miss_rate']:>9.1f}% {ci_str:>20}\"\n",
    "        )\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def analyze_category_by_difficulty(sim_df, coder_cols):\n",
    "    \"\"\"Analyze miss rates by category x difficulty interaction.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): simulation results from run_simulation()\n",
    "        coder_cols (list[str]): list of column names\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: category x difficulty interaction miss rates matrix\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CATEGORY × DIFFICULTY INTERACTION\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for category in QUERY_CATEGORIES.keys():\n",
    "        for diff in [\"Easy\", \"Medium\", \"Hard\"]:\n",
    "            subset = sim_df[\n",
    "                (sim_df[\"category\"] == category) & (sim_df[\"difficulty\"] == diff)\n",
    "            ]\n",
    "            union_hits = subset[\"union_hit\"].sum()\n",
    "\n",
    "            if union_hits == 0:\n",
    "                continue\n",
    "\n",
    "            miss_rates = []\n",
    "            for col in coder_cols:\n",
    "                coder = col.replace(\"_hit\", \"\")\n",
    "                misses = subset[f\"{coder}_miss\"].sum()\n",
    "                miss_rates.append(misses / union_hits * 100)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"category\": category,\n",
    "                    \"difficulty\": diff,\n",
    "                    \"union_hits\": union_hits,\n",
    "                    \"avg_miss_rate\": np.mean(miss_rates),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Pivot for display\n",
    "    pivot = results_df.pivot(\n",
    "        index=\"category\", columns=\"difficulty\", values=\"avg_miss_rate\"\n",
    "    )\n",
    "    pivot = pivot.reindex(columns=[\"Easy\", \"Medium\", \"Hard\"])\n",
    "\n",
    "    print(\"\\nAverage Miss Rate (%) by Category and Difficulty:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(pivot.round(1).fillna(\"-\").to_string())\n",
    "\n",
    "    return results_df, pivot\n",
    "\n",
    "\n",
    "def analyze_coder_by_category(sim_df, coder_cols):\n",
    "    \"\"\"Analyze miss rates by coder.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): simulation results from run_simulation()\n",
    "        coder_cols (list[str]): list of column names\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: by-coder miss rates matrix\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CODER × CATEGORY INTERACTION\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for category in QUERY_CATEGORIES.keys():\n",
    "        cat_df = sim_df[sim_df[\"category\"] == category]\n",
    "        cat_union = cat_df[\"union_hit\"].sum()\n",
    "\n",
    "        if cat_union == 0:\n",
    "            continue\n",
    "\n",
    "        for col in coder_cols:\n",
    "            coder = col.replace(\"_hit\", \"\")\n",
    "            misses = cat_df[f\"{coder}_miss\"].sum()\n",
    "            miss_rate = misses / cat_union * 100\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"category\": category,\n",
    "                    \"coder\": coder,\n",
    "                    \"union_hits\": cat_union,\n",
    "                    \"misses\": misses,\n",
    "                    \"miss_rate\": miss_rate,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Pivot for display\n",
    "    pivot = results_df.pivot(index=\"category\", columns=\"coder\", values=\"miss_rate\")\n",
    "\n",
    "    print(\"\\nMiss Rate (%) by Category and Coder:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(pivot.round(1).to_string())\n",
    "\n",
    "    # Identify worst coder per category\n",
    "    print(\"\\nWorst Performer by Category:\")\n",
    "    for cat in QUERY_CATEGORIES.keys():\n",
    "        cat_data = results_df[results_df[\"category\"] == cat]\n",
    "        if len(cat_data) > 0:\n",
    "            worst = cat_data.loc[cat_data[\"miss_rate\"].idxmax()]\n",
    "            if worst[\"miss_rate\"] > 0:\n",
    "                print(\n",
    "                    f\"  {cat}: {worst['coder']} ({worst['miss_rate']:.1f}% miss rate)\"\n",
    "                )\n",
    "\n",
    "    return results_df, pivot\n",
    "\n",
    "\n",
    "def analyze_by_contract(sim_df, coder_cols):\n",
    "    \"\"\"Analyze miss rates by individual contract.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): simulation results from run_simulation()\n",
    "        coder_cols (list[str]): list of column names\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: by-contract miss rates matrix\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CONTRACT-LEVEL ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for contract in sim_df[\"contract\"].unique():\n",
    "        con_df = sim_df[sim_df[\"contract\"] == contract]\n",
    "        con_union = con_df[\"union_hit\"].sum()\n",
    "        difficulty = con_df[\"difficulty\"].iloc[0]\n",
    "\n",
    "        if con_union == 0:\n",
    "            continue\n",
    "\n",
    "        con_result = {\n",
    "            \"contract\": contract,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"union_hits\": con_union,\n",
    "        }\n",
    "\n",
    "        miss_rates = []\n",
    "        for col in coder_cols:\n",
    "            coder = col.replace(\"_hit\", \"\")\n",
    "            misses = con_df[f\"{coder}_miss\"].sum()\n",
    "            miss_rate = misses / con_union * 100\n",
    "            con_result[f\"{coder}_miss\"] = miss_rate\n",
    "            miss_rates.append(miss_rate)\n",
    "\n",
    "        con_result[\"avg_miss_rate\"] = np.mean(miss_rates)\n",
    "        con_result[\"max_miss_rate\"] = np.max(miss_rates)\n",
    "        con_result[\"coder_variance\"] = np.std(miss_rates)\n",
    "\n",
    "        results.append(con_result)\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"avg_miss_rate\", ascending=False)\n",
    "\n",
    "    print(\n",
    "        f\"\\n{'Contract':<18} {'Diff':<8} {'Hits':>6} {'Avg Miss':>10} {'Max Miss':>10} {'Variance':>10}\"\n",
    "    )\n",
    "    print(\"-\" * 70)\n",
    "    for _, row in results_df.iterrows():\n",
    "        print(\n",
    "            f\"{row['contract']:<18} {row['difficulty']:<8} {row['union_hits']:>6} \"\n",
    "            f\"{row['avg_miss_rate']:>9.1f}% {row['max_miss_rate']:>9.1f}% {row['coder_variance']:>9.1f}\"\n",
    "        )\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def analyze_query_level(sim_df, coder_cols):\n",
    "    \"\"\"Analyze miss rates by simulated query.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): simulation results from run_simulation()\n",
    "        coder_cols (list[str]): list of column names\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: by-query miss rates matrix\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"QUERY-LEVEL ANALYSIS (Top 15 by miss rate)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for query in QUERY_SCENARIOS.keys():\n",
    "        q_df = sim_df[sim_df[\"query\"] == query]\n",
    "        q_union = q_df[\"union_hit\"].sum()\n",
    "\n",
    "        if q_union == 0:\n",
    "            continue\n",
    "\n",
    "        miss_rates = []\n",
    "        for col in coder_cols:\n",
    "            coder = col.replace(\"_hit\", \"\")\n",
    "            misses = q_df[f\"{coder}_miss\"].sum()\n",
    "            miss_rates.append(misses / q_union * 100)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"query\": query,\n",
    "                \"category\": QUERY_TO_CATEGORY.get(query, \"Unknown\"),\n",
    "                \"union_hits\": q_union,\n",
    "                \"avg_miss_rate\": np.mean(miss_rates),\n",
    "                \"max_miss_rate\": np.max(miss_rates),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"avg_miss_rate\", ascending=False)\n",
    "\n",
    "    print(f\"\\n{'Query':<30} {'Category':<18} {'Hits':>6} {'Avg Miss':>10}\")\n",
    "    print(\"-\" * 70)\n",
    "    for _, row in results_df.head(15).iterrows():\n",
    "        print(\n",
    "            f\"{row['query']:<30} {row['category']:<18} {row['union_hits']:>6} \"\n",
    "            f\"{row['avg_miss_rate']:>9.1f}%\"\n",
    "        )\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def compute_risk_scores(sim_df, coder_cols, category_df, difficulty_df):\n",
    "    \"\"\"Analyze miss rates by query category.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): simulation results from run_simulation()\n",
    "        coder_cols (list[str]): list of column names\n",
    "        category_df (pd.DataFrame): by-category simulation results\n",
    "        difficulty_df (pd.DataFrame): by-difficulty simulation results\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.DataFrame] tuple containing\n",
    "            - category_df: by-category risk matrix\n",
    "            - difficulty_df: by-difficulty risk matrix\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RISK PRIORITIZATION\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Category risk = miss rate × union hits (impact-weighted)\n",
    "    category_df = category_df.copy()\n",
    "    category_df[\"risk_score\"] = (\n",
    "        category_df[\"avg_miss_rate\"] * category_df[\"union_hits\"] / 100\n",
    "    )\n",
    "    category_df = category_df.sort_values(\"risk_score\", ascending=False)\n",
    "\n",
    "    print(\"\\nCategory Risk Scores (miss rate × hit frequency):\")\n",
    "    print(\"-\" * 50)\n",
    "    for _, row in category_df.iterrows():\n",
    "        print(\n",
    "            f\"  {row['category']:<18} Risk: {row['risk_score']:>6.1f} \"\n",
    "            f\"(Miss: {row['avg_miss_rate']:.1f}%, Hits: {row['union_hits']})\"\n",
    "        )\n",
    "\n",
    "    # High-risk combinations (category × difficulty)\n",
    "    print(\"\\nHigh-Risk Category × Difficulty Combinations:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    high_risk = []\n",
    "    for category in QUERY_CATEGORIES.keys():\n",
    "        for diff in [\"Medium\", \"Hard\"]:  # Skip Easy (usually 0%)\n",
    "            subset = sim_df[\n",
    "                (sim_df[\"category\"] == category) & (sim_df[\"difficulty\"] == diff)\n",
    "            ]\n",
    "            union_hits = subset[\"union_hit\"].sum()\n",
    "\n",
    "            if union_hits == 0:\n",
    "                continue\n",
    "\n",
    "            miss_rates = []\n",
    "            for col in coder_cols:\n",
    "                coder = col.replace(\"_hit\", \"\")\n",
    "                misses = subset[f\"{coder}_miss\"].sum()\n",
    "                miss_rates.append(misses / union_hits * 100)\n",
    "\n",
    "            avg_miss = np.mean(miss_rates)\n",
    "            if avg_miss > 20:  # Threshold for \"high risk\"\n",
    "                high_risk.append(\n",
    "                    {\n",
    "                        \"category\": category,\n",
    "                        \"difficulty\": diff,\n",
    "                        \"miss_rate\": avg_miss,\n",
    "                        \"union_hits\": union_hits,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    high_risk_df = pd.DataFrame(high_risk).sort_values(\"miss_rate\", ascending=False)\n",
    "\n",
    "    for _, row in high_risk_df.iterrows():\n",
    "        print(\n",
    "            f\"  {row['category']:<18} + {row['difficulty']:<8} → {row['miss_rate']:.1f}% miss rate\"\n",
    "        )\n",
    "\n",
    "    return category_df, high_risk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6222866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_miss_rates(category_df, output_path=None):\n",
    "    \"\"\"Plot miss rates by category.\n",
    "\n",
    "    Args:\n",
    "        category_df (pd.DataFrame): by-category miss rates matrix\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    df = category_df.sort_values(\"avg_miss_rate\", ascending=True)\n",
    "\n",
    "    colors = plt.cm.RdYlGn_r(df[\"avg_miss_rate\"] / df[\"avg_miss_rate\"].max())\n",
    "\n",
    "    bars = ax.barh(\n",
    "        df[\"category\"],\n",
    "        df[\"avg_miss_rate\"],\n",
    "        color=colors,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    # Error bars\n",
    "    if \"ci_lower\" in df.columns and \"ci_upper\" in df.columns:\n",
    "        xerr_lower = df[\"avg_miss_rate\"] - df[\"ci_lower\"]\n",
    "        xerr_upper = df[\"ci_upper\"] - df[\"avg_miss_rate\"]\n",
    "        ax.errorbar(\n",
    "            df[\"avg_miss_rate\"],\n",
    "            df[\"category\"],\n",
    "            xerr=[xerr_lower, xerr_upper],\n",
    "            fmt=\"none\",\n",
    "            color=\"black\",\n",
    "            capsize=3,\n",
    "        )\n",
    "\n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, df[\"avg_miss_rate\"]):\n",
    "        ax.text(\n",
    "            val + 1,\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{val:.1f}%\",\n",
    "            va=\"center\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Average Single-Coder Miss Rate (%)\", fontsize=12)\n",
    "    ax.set_title(\n",
    "        \"Query Miss Rates by Category\\n(Higher = More risk from single-coder production)\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.set_xlim(0, max(df[\"avg_miss_rate\"]) * 1.3)\n",
    "\n",
    "    # Add vertical line at overall average\n",
    "    overall_avg = df[\"avg_miss_rate\"].mean()\n",
    "    ax.axvline(\n",
    "        overall_avg,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=f\"Overall avg: {overall_avg:.1f}%\",\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_difficulty_miss_rates(difficulty_df, output_path=None):\n",
    "    \"\"\"Plot miss rates by difficulty.\n",
    "\n",
    "    Args:\n",
    "        difficulty_df (pd.DataFrame): by-difficulty miss rates matrix\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Order by difficulty\n",
    "    diff_order = [\"Easy\", \"Medium\", \"Hard\"]\n",
    "    df = difficulty_df.set_index(\"difficulty\").reindex(diff_order).reset_index()\n",
    "\n",
    "    colors_map = {\"Easy\": \"forestgreen\", \"Medium\": \"gold\", \"Hard\": \"firebrick\"}\n",
    "    bar_colors = [colors_map[d] for d in df[\"difficulty\"]]\n",
    "\n",
    "    x_pos = np.arange(len(df))\n",
    "    bars = ax.bar(\n",
    "        x_pos, df[\"avg_miss_rate\"], color=bar_colors, edgecolor=\"black\", linewidth=1\n",
    "    )\n",
    "\n",
    "    # Error bars\n",
    "    if \"ci_lower\" in df.columns and \"ci_upper\" in df.columns:\n",
    "        yerr_lower = df[\"avg_miss_rate\"] - df[\"ci_lower\"]\n",
    "        yerr_upper = df[\"ci_upper\"] - df[\"avg_miss_rate\"]\n",
    "        ax.errorbar(\n",
    "            x_pos,\n",
    "            df[\"avg_miss_rate\"],\n",
    "            yerr=[yerr_lower, yerr_upper],\n",
    "            fmt=\"none\",\n",
    "            color=\"black\",\n",
    "            capsize=8,\n",
    "            capthick=2,\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(df[\"difficulty\"])\n",
    "    ax.set_xlabel(\"Contract Difficulty\", fontsize=12)\n",
    "    ax.set_ylabel(\"Average Miss Rate (%)\", fontsize=12)\n",
    "    ax.set_title(\"Query Miss Rates by Contract Difficulty (with 95% CI)\", fontsize=14)\n",
    "    ax.set_ylim(\n",
    "        0,\n",
    "        max(\n",
    "            df[\"avg_miss_rate\"].max(),\n",
    "            df[\"ci_upper\"].max() if \"ci_upper\" in df.columns else 0,\n",
    "        )\n",
    "        * 1.3,\n",
    "    )\n",
    "\n",
    "    # Add value labels\n",
    "    for i, row in df.iterrows():\n",
    "        ypos = row[\"avg_miss_rate\"]\n",
    "        if \"ci_upper\" in df.columns:\n",
    "            ypos = row[\"ci_upper\"] + 2\n",
    "        ax.text(\n",
    "            i,\n",
    "            ypos,\n",
    "            f\"{row['avg_miss_rate']:.1f}%\",\n",
    "            ha=\"center\",\n",
    "            fontsize=11,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_coder_category_heatmap(coder_category_pivot, output_path=None):\n",
    "    \"\"\"Heatmap of coder x category miss rates.\n",
    "\n",
    "    Args:\n",
    "        coder_category_pivot (pd.DataFrame): pivot table by coder and query category\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    sns.heatmap(\n",
    "        coder_category_pivot,\n",
    "        annot=True,\n",
    "        fmt=\".1f\",\n",
    "        cmap=\"RdYlGn_r\",\n",
    "        cbar_kws={\"label\": \"Miss Rate (%)\"},\n",
    "        ax=ax,\n",
    "        vmin=0,\n",
    "        vmax=coder_category_pivot.max().max() * 1.1,\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"white\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Miss Rates by Coder and Query Category (%)\\n(Red = Higher miss rate)\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.set_xlabel(\"Coder\", fontsize=12)\n",
    "    ax.set_ylabel(\"Query Category\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_difficulty_category_heatmap(cat_diff_pivot, output_path=None):\n",
    "    \"\"\"Heatmap of difficulty x category miss rates.\n",
    "\n",
    "    Args:\n",
    "        cat_diff_pivot (pd.DataFrame): pivot table by difficulty and query category\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Reorder columns\n",
    "    cat_diff_pivot = cat_diff_pivot.reindex(columns=[\"Easy\", \"Medium\", \"Hard\"])\n",
    "\n",
    "    sns.heatmap(\n",
    "        cat_diff_pivot,\n",
    "        annot=True,\n",
    "        fmt=\".1f\",\n",
    "        cmap=\"RdYlGn_r\",\n",
    "        cbar_kws={\"label\": \"Avg Miss Rate (%)\"},\n",
    "        ax=ax,\n",
    "        vmin=0,\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"white\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Miss Rates by Query Category and Contract Difficulty (%)\", fontsize=14\n",
    "    )\n",
    "    ax.set_xlabel(\"Contract Difficulty\", fontsize=12)\n",
    "    ax.set_ylabel(\"Query Category\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_contract_heatmap(contract_df, coder_cols, output_path=None):\n",
    "    \"\"\"Heatmap of contract x category miss rates.\n",
    "\n",
    "    Args:\n",
    "        contract_df (pd.DataFrame): by-contract miss rates matrix\n",
    "        coder_cols (list[str]): list of column names\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Prepare data\n",
    "    miss_cols = [c.replace(\"_hit\", \"_miss\") for c in coder_cols]\n",
    "    plot_data = contract_df.set_index(\"contract\")[miss_cols].copy()\n",
    "    plot_data.columns = [c.replace(\"_miss\", \"\") for c in plot_data.columns]\n",
    "\n",
    "    # Add difficulty annotation\n",
    "    plot_data.index = [\n",
    "        f\"{idx} ({contract_df[contract_df['contract']==idx]['difficulty'].iloc[0]})\"\n",
    "        for idx in plot_data.index\n",
    "    ]\n",
    "\n",
    "    sns.heatmap(\n",
    "        plot_data,\n",
    "        annot=True,\n",
    "        fmt=\".0f\",\n",
    "        cmap=\"RdYlGn_r\",\n",
    "        cbar_kws={\"label\": \"Miss Rate (%)\"},\n",
    "        ax=ax,\n",
    "        vmin=0,\n",
    "        vmax=60,\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"white\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Miss Rates by Contract and Coder (%)\\n(Red = Higher miss rate)\", fontsize=14\n",
    "    )\n",
    "    ax.set_xlabel(\"Coder\", fontsize=12)\n",
    "    ax.set_ylabel(\"Contract (Difficulty)\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_miss_rate_distribution(sim_df, coder_cols, output_path=None):\n",
    "    \"\"\"Distribution of miss rates across query x contract combinations.\n",
    "\n",
    "    Args:\n",
    "        sim_df (pd.DataFrame): simulation results matrix\n",
    "        coder_cols (list[str]): list of column names\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Left: Histogram of miss indicators\n",
    "    all_misses = []\n",
    "    for col in coder_cols:\n",
    "        coder = col.replace(\"_hit\", \"\")\n",
    "        # Only count where union hit = 1\n",
    "        misses = sim_df[sim_df[\"union_hit\"] == 1][f\"{coder}_miss\"].values\n",
    "        all_misses.extend(misses)\n",
    "\n",
    "    ax1 = axes[0]\n",
    "    miss_rate = np.mean(all_misses) * 100\n",
    "    ax1.bar(\n",
    "        [\"Hit\", \"Miss\"],\n",
    "        [1 - np.mean(all_misses), np.mean(all_misses)],\n",
    "        color=[\"forestgreen\", \"firebrick\"],\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "    ax1.set_ylabel(\"Proportion\", fontsize=12)\n",
    "    ax1.set_title(\n",
    "        f\"Single-Coder Query Outcomes\\n(Miss rate: {miss_rate:.1f}%)\", fontsize=14\n",
    "    )\n",
    "    ax1.set_ylim(0, 1)\n",
    "\n",
    "    # Right: Miss rate by coder WITH ERROR BARS\n",
    "    ax2 = axes[1]\n",
    "    coder_miss_rates = []\n",
    "    coder_cis = []  # Store CI bounds\n",
    "    coder_names = []\n",
    "\n",
    "    for col in sorted(coder_cols):\n",
    "        coder = col.replace(\"_hit\", \"\")\n",
    "        misses = sim_df[sim_df[\"union_hit\"] == 1][f\"{coder}_miss\"].values\n",
    "\n",
    "        # Compute miss rate and bootstrap CI\n",
    "        miss_rate = np.mean(misses) * 100\n",
    "        point, lower, upper = bootstrap_ci(misses)\n",
    "\n",
    "        coder_miss_rates.append(miss_rate)\n",
    "        coder_cis.append((lower * 100, upper * 100))\n",
    "        coder_names.append(coder)\n",
    "\n",
    "    colors = [\"steelblue\", \"darkorange\", \"forestgreen\"]\n",
    "    x_pos = np.arange(len(coder_names))\n",
    "\n",
    "    # Calculate error bar sizes\n",
    "    yerr_lower = [rate - ci[0] for rate, ci in zip(coder_miss_rates, coder_cis)]\n",
    "    yerr_upper = [ci[1] - rate for rate, ci in zip(coder_miss_rates, coder_cis)]\n",
    "\n",
    "    bars = ax2.bar(\n",
    "        x_pos, coder_miss_rates, color=colors[: len(coder_names)], edgecolor=\"black\"\n",
    "    )\n",
    "    ax2.errorbar(\n",
    "        x_pos,\n",
    "        coder_miss_rates,\n",
    "        yerr=[yerr_lower, yerr_upper],\n",
    "        fmt=\"none\",\n",
    "        color=\"black\",\n",
    "        capsize=5,\n",
    "        capthick=2,\n",
    "    )\n",
    "\n",
    "    ax2.axhline(\n",
    "        np.mean(coder_miss_rates),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Avg: {np.mean(coder_miss_rates):.1f}%\",\n",
    "    )\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(coder_names)\n",
    "    ax2.set_ylabel(\"Miss Rate (%)\", fontsize=12)\n",
    "    ax2.set_title(\"Miss Rate by Coder (with 95% CI)\", fontsize=14)\n",
    "    ax2.legend()\n",
    "\n",
    "    # Add value labels above error bars\n",
    "    for i, (val, ci) in enumerate(zip(coder_miss_rates, coder_cis)):\n",
    "        ax2.text(i, ci[1] + 1, f\"{val:.1f}%\", ha=\"center\", fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_category_difficulty_grouped(\n",
    "    cat_diff_df, sim_df=None, coder_cols=None, output_path=None\n",
    "):\n",
    "    \"\"\"Grouped bar chart of miss rates by category and difficulty.\n",
    "\n",
    "    Args:\n",
    "        cat_diff_df (pd.DataFrame): by-category simulation results\n",
    "        sim_df (pd.DataFrame): simulation results\n",
    "        coder_cols (list[str]): list of column names\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    categories = list(QUERY_CATEGORIES.keys())\n",
    "    difficulties = [\"Easy\", \"Medium\", \"Hard\"]\n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.25\n",
    "\n",
    "    colors = {\"Easy\": \"forestgreen\", \"Medium\": \"gold\", \"Hard\": \"firebrick\"}\n",
    "\n",
    "    for i, diff in enumerate(difficulties):\n",
    "        values = []\n",
    "        errors_lower = []\n",
    "        errors_upper = []\n",
    "\n",
    "        for cat in categories:\n",
    "            row = cat_diff_df[\n",
    "                (cat_diff_df[\"category\"] == cat) & (cat_diff_df[\"difficulty\"] == diff)\n",
    "            ]\n",
    "            if len(row) > 0:\n",
    "                val = row[\"avg_miss_rate\"].iloc[0]\n",
    "                values.append(val)\n",
    "\n",
    "                # Compute bootstrap CI if sim_df provided\n",
    "                if sim_df is not None and coder_cols is not None:\n",
    "                    subset = sim_df[\n",
    "                        (sim_df[\"category\"] == cat) & (sim_df[\"difficulty\"] == diff)\n",
    "                    ]\n",
    "                    if subset[\"union_hit\"].sum() > 0:\n",
    "                        miss_indicators = []\n",
    "                        for col in coder_cols:\n",
    "                            coder = col.replace(\"_hit\", \"\")\n",
    "                            miss_indicators.extend(\n",
    "                                subset[subset[\"union_hit\"] == 1][f\"{coder}_miss\"].values\n",
    "                            )\n",
    "\n",
    "                        if len(miss_indicators) > 2:\n",
    "                            point, lower, upper = bootstrap_ci(miss_indicators)\n",
    "                            errors_lower.append(max(0, val - lower * 100))\n",
    "                            errors_upper.append(max(0, upper * 100 - val))\n",
    "                        else:\n",
    "                            errors_lower.append(0)\n",
    "                            errors_upper.append(0)\n",
    "                    else:\n",
    "                        errors_lower.append(0)\n",
    "                        errors_upper.append(0)\n",
    "                else:\n",
    "                    errors_lower.append(0)\n",
    "                    errors_upper.append(0)\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors_lower.append(0)\n",
    "                errors_upper.append(0)\n",
    "\n",
    "        bars = ax.bar(\n",
    "            x + i * width,\n",
    "            values,\n",
    "            width,\n",
    "            label=diff,\n",
    "            color=colors[diff],\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        # Add error bars only for non-zero values with valid errors\n",
    "        if sim_df is not None:\n",
    "            for j, (val, el, eu) in enumerate(zip(values, errors_lower, errors_upper)):\n",
    "                if val > 0 and (el > 0 or eu > 0):\n",
    "                    ax.errorbar(\n",
    "                        x[j] + i * width,\n",
    "                        val,\n",
    "                        yerr=[[el], [eu]],\n",
    "                        fmt=\"none\",\n",
    "                        color=\"black\",\n",
    "                        capsize=3,\n",
    "                        capthick=1,\n",
    "                    )\n",
    "\n",
    "    ax.set_xlabel(\"Query Category\", fontsize=12)\n",
    "    ax.set_ylabel(\"Average Miss Rate (%)\", fontsize=12)\n",
    "    ax.set_title(\"Miss Rates by Query Category and Contract Difficulty\", fontsize=14)\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(categories, rotation=45, ha=\"right\")\n",
    "    ax.legend(title=\"Difficulty\")\n",
    "    ax.set_ylim(0, max(cat_diff_df[\"avg_miss_rate\"]) * 1.2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_agreement_comparison(results_df, output_path=None):\n",
    "    \"\"\"Create grouped bar chart comparing Round 1 vs Round 2 agreement by difficulty.\n",
    "\n",
    "    Args:\n",
    "        results_df (pd.DataFrame): results matrix from compute_agreement_matrix()\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Extract Round × Difficulty data\n",
    "    r1_data = results_df[results_df[\"Segment\"].str.startswith(\"R1\")]\n",
    "    r2_data = results_df[results_df[\"Segment\"].str.startswith(\"R2\")]\n",
    "\n",
    "    difficulties = [\"Easy\", \"Medium\", \"Hard\"]\n",
    "    x = np.arange(len(difficulties))\n",
    "    width = 0.35\n",
    "\n",
    "    # Extract rates and CIs for Round 1\n",
    "    r1_rates = []\n",
    "    r1_ci_lower = []\n",
    "    r1_ci_upper = []\n",
    "    for d in difficulties:\n",
    "        row = r1_data[r1_data[\"Segment\"] == f\"R1 {d}\"]\n",
    "        if len(row) > 0:\n",
    "            rate = row[\"agreement_rate\"].values[0] * 100\n",
    "            ci_low = (\n",
    "                row[\"ci_lower\"].values[0] * 100 if \"ci_lower\" in row.columns else rate\n",
    "            )\n",
    "            ci_high = (\n",
    "                row[\"ci_upper\"].values[0] * 100 if \"ci_upper\" in row.columns else rate\n",
    "            )\n",
    "            r1_rates.append(rate)\n",
    "            r1_ci_lower.append(rate - ci_low)\n",
    "            r1_ci_upper.append(ci_high - rate)\n",
    "        else:\n",
    "            r1_rates.append(0)\n",
    "            r1_ci_lower.append(0)\n",
    "            r1_ci_upper.append(0)\n",
    "\n",
    "    # Extract rates and CIs for Round 2\n",
    "    r2_rates = []\n",
    "    r2_ci_lower = []\n",
    "    r2_ci_upper = []\n",
    "    for d in difficulties:\n",
    "        row = r2_data[r2_data[\"Segment\"] == f\"R2 {d}\"]\n",
    "        if len(row) > 0:\n",
    "            rate = row[\"agreement_rate\"].values[0] * 100\n",
    "            ci_low = (\n",
    "                row[\"ci_lower\"].values[0] * 100 if \"ci_lower\" in row.columns else rate\n",
    "            )\n",
    "            ci_high = (\n",
    "                row[\"ci_upper\"].values[0] * 100 if \"ci_upper\" in row.columns else rate\n",
    "            )\n",
    "            r2_rates.append(rate)\n",
    "            r2_ci_lower.append(rate - ci_low)\n",
    "            r2_ci_upper.append(ci_high - rate)\n",
    "        else:\n",
    "            r2_rates.append(0)\n",
    "            r2_ci_lower.append(0)\n",
    "            r2_ci_upper.append(0)\n",
    "\n",
    "    # Plot bars\n",
    "    bars1 = ax.bar(\n",
    "        x - width / 2, r1_rates, width, label=\"Round 1 (Role-level)\", color=\"steelblue\"\n",
    "    )\n",
    "    bars2 = ax.bar(\n",
    "        x + width / 2,\n",
    "        r2_rates,\n",
    "        width,\n",
    "        label=\"Round 2 (Service-level)\",\n",
    "        color=\"darkorange\",\n",
    "    )\n",
    "\n",
    "    # Add error bars\n",
    "    ax.errorbar(\n",
    "        x - width / 2,\n",
    "        r1_rates,\n",
    "        yerr=[r1_ci_lower, r1_ci_upper],\n",
    "        fmt=\"none\",\n",
    "        color=\"black\",\n",
    "        capsize=5,\n",
    "        capthick=1.5,\n",
    "    )\n",
    "    ax.errorbar(\n",
    "        x + width / 2,\n",
    "        r2_rates,\n",
    "        yerr=[r2_ci_lower, r2_ci_upper],\n",
    "        fmt=\"none\",\n",
    "        color=\"black\",\n",
    "        capsize=5,\n",
    "        capthick=1.5,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Contract Difficulty\", fontsize=12)\n",
    "    ax.set_ylabel(\"Classification Agreement (%)\", fontsize=12)\n",
    "    ax.set_title(\n",
    "        \"Classification Agreement by Round and Difficulty\\n(with 95% Confidence Intervals)\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(difficulties)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set_ylim(0, 115)  # Extra room for labels and error bars\n",
    "\n",
    "    # Add value labels above error bars\n",
    "    for i, (r1, r1_u, r2, r2_u) in enumerate(\n",
    "        zip(r1_rates, r1_ci_upper, r2_rates, r2_ci_upper)\n",
    "    ):\n",
    "        if r1 > 0:\n",
    "            ax.annotate(\n",
    "                f\"{r1:.0f}%\",\n",
    "                xy=(x[i] - width / 2, r1 + r1_u + 2),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=9,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "        if r2 > 0:\n",
    "            ax.annotate(\n",
    "                f\"{r2:.0f}%\",\n",
    "                xy=(x[i] + width / 2, r2 + r2_u + 2),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=9,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "    # Add annotation for key finding\n",
    "    if len(r1_rates) > 2 and len(r2_rates) > 2 and r1_rates[2] > 0 and r2_rates[2] > 0:\n",
    "        improvement = r2_rates[2] - r1_rates[2]\n",
    "        ax.annotate(\n",
    "            f\"+{improvement:.0f}pp\",\n",
    "            xy=(x[2], max(r1_rates[2], r2_rates[2]) + 8),\n",
    "            fontsize=11,\n",
    "            fontweight=\"bold\",\n",
    "            color=\"darkgreen\",\n",
    "            ha=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_coder_profiles(pivot, top_prefixes, output_path=None):\n",
    "    \"\"\"Create radar/spider chart of coder prefix usage profiles.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        pivot (pd.DataFrame): pivot table prefixes by-coder from analyze_coder_profiles()\n",
    "        top_prefixes (list[str]): list of top prefixes across all coders from analyze_coder_profiles()\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    from math import pi\n",
    "\n",
    "    categories = top_prefixes\n",
    "    N = len(categories)\n",
    "\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]  # Complete the loop\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "    colors = {\"D\": \"#1f77b4\", \"G\": \"#2ca02c\", \"W\": \"#ff7f0e\"}\n",
    "\n",
    "    for coder in pivot.index:\n",
    "        values = pivot.loc[coder, top_prefixes].values.tolist()\n",
    "        values += values[:1]  # Complete the loop\n",
    "\n",
    "        ax.plot(\n",
    "            angles,\n",
    "            values,\n",
    "            \"o-\",\n",
    "            linewidth=2,\n",
    "            label=coder,\n",
    "            color=colors.get(coder, \"gray\"),\n",
    "            markersize=6,\n",
    "        )\n",
    "        ax.fill(angles, values, alpha=0.15, color=colors.get(coder, \"gray\"))\n",
    "\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels([f\"{p}xxx\" for p in categories], fontsize=11)\n",
    "    ax.set_title(\n",
    "        \"Coder NAICS Prefix Usage Profiles\\n(% of each coder's assignments)\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1.0), fontsize=11)\n",
    "\n",
    "    # Add gridlines\n",
    "    ax.set_ylim(0, max(pivot[top_prefixes].max()) * 1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_miss_rate_heatmap(contract_df, output_path=None):\n",
    "    \"\"\"Create heatmap of miss rates by contract and coder.\n",
    "\n",
    "    Args:\n",
    "        miss_rates_df (pd.DataFrame): matrix of miss rates from compute_miss_rates()\n",
    "        output_path (str, optional): output filepath. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Handle both naming conventions\n",
    "    if \"contract\" in contract_df.columns:\n",
    "        # From analyze_by_contract()\n",
    "        coder_cols = [\n",
    "            c\n",
    "            for c in contract_df.columns\n",
    "            if c.endswith(\"_miss\") and c not in [\"avg_miss_rate\", \"max_miss_rate\"]\n",
    "        ]\n",
    "        plot_data = contract_df.set_index(\"contract\")[coder_cols].copy()\n",
    "        plot_data.columns = [c.replace(\"_miss\", \"\") for c in plot_data.columns]\n",
    "\n",
    "        # Add difficulty to index\n",
    "        if \"difficulty\" in contract_df.columns:\n",
    "            new_index = [\n",
    "                f\"{contract}\\n({contract_df[contract_df['contract']==contract]['difficulty'].iloc[0]})\"\n",
    "                for contract in contract_df[\"contract\"]\n",
    "            ]\n",
    "            plot_data.index = new_index\n",
    "    else:\n",
    "        # Original format with Contract, D_Miss%, etc.\n",
    "        coder_cols = [c for c in contract_df.columns if c.endswith(\"_Miss%\")]\n",
    "        plot_data = contract_df.set_index(\"Contract\")[coder_cols].copy()\n",
    "        plot_data.columns = [c.replace(\"_Miss%\", \"\") for c in plot_data.columns]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "    sns.heatmap(\n",
    "        plot_data,\n",
    "        annot=True,\n",
    "        fmt=\".0f\",\n",
    "        cmap=\"RdYlGn_r\",\n",
    "        vmin=0,\n",
    "        vmax=60,\n",
    "        ax=ax,\n",
    "        cbar_kws={\"label\": \"Miss Rate (%)\"},\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"white\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Query Miss Rates by Contract and Coder (%)\\n(Red = Higher miss rate)\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.set_xlabel(\"Coder\", fontsize=12)\n",
    "    ax.set_ylabel(\"Contract (Difficulty)\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_round_comparison_slope(results_df, output_path=None):\n",
    "    \"\"\"Create slope chart showing Round 1 → Round 2 improvement with CI bands.\n",
    "\n",
    "    Args:\n",
    "        results_df (pd.DataFrame): simulation results from run_simulation()\n",
    "\n",
    "    Returns:\n",
    "        tuple[Figure, Axes] tuple containing\n",
    "            - fig: matplotlib Figure object\n",
    "            - ax: matplotlib Axes object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    difficulties = [\"Hard\"]\n",
    "    colors = {\"Hard\": \"firebrick\"}\n",
    "\n",
    "    for i, diff in enumerate(difficulties):\n",
    "        # Get R1 data\n",
    "        r1_row = results_df[results_df[\"Segment\"] == f\"R1 {diff}\"]\n",
    "        r2_row = results_df[results_df[\"Segment\"] == f\"R2 {diff}\"]\n",
    "\n",
    "        if len(r1_row) > 0 and len(r2_row) > 0:\n",
    "            r1_rate = r1_row[\"agreement_rate\"].values[0] * 100\n",
    "            r2_rate = r2_row[\"agreement_rate\"].values[0] * 100\n",
    "\n",
    "            r1_ci_low = (\n",
    "                r1_row[\"ci_lower\"].values[0] * 100\n",
    "                if \"ci_lower\" in r1_row.columns\n",
    "                else r1_rate\n",
    "            )\n",
    "            r1_ci_high = (\n",
    "                r1_row[\"ci_upper\"].values[0] * 100\n",
    "                if \"ci_upper\" in r1_row.columns\n",
    "                else r1_rate\n",
    "            )\n",
    "            r2_ci_low = (\n",
    "                r2_row[\"ci_lower\"].values[0] * 100\n",
    "                if \"ci_lower\" in r2_row.columns\n",
    "                else r2_rate\n",
    "            )\n",
    "            r2_ci_high = (\n",
    "                r2_row[\"ci_upper\"].values[0] * 100\n",
    "                if \"ci_upper\" in r2_row.columns\n",
    "                else r2_rate\n",
    "            )\n",
    "\n",
    "            # Plot line\n",
    "            ax.plot(\n",
    "                [0, 1],\n",
    "                [r1_rate, r2_rate],\n",
    "                \"o-\",\n",
    "                color=colors[diff],\n",
    "                linewidth=3,\n",
    "                markersize=10,\n",
    "                label=diff,\n",
    "            )\n",
    "\n",
    "            # Add CI error bars at each point\n",
    "            ax.errorbar(\n",
    "                0,\n",
    "                r1_rate,\n",
    "                yerr=[[r1_rate - r1_ci_low], [r1_ci_high - r1_rate]],\n",
    "                fmt=\"none\",\n",
    "                color=colors[diff],\n",
    "                capsize=5,\n",
    "                capthick=2,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "            ax.errorbar(\n",
    "                1,\n",
    "                r2_rate,\n",
    "                yerr=[[r2_rate - r2_ci_low], [r2_ci_high - r2_rate]],\n",
    "                fmt=\"none\",\n",
    "                color=colors[diff],\n",
    "                capsize=5,\n",
    "                capthick=2,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "\n",
    "            # Add improvement annotation\n",
    "            improvement = r2_rate - r1_rate\n",
    "            mid_y = (r1_rate + r2_rate) / 2\n",
    "            ax.annotate(\n",
    "                f\"+{improvement:.0f}pp\",\n",
    "                xy=(0.5, mid_y),\n",
    "                fontsize=10,\n",
    "                ha=\"center\",\n",
    "                color=colors[diff],\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "    ax.set_xlim(-0.2, 1.2)\n",
    "    ax.set_ylim(0, 110)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(\n",
    "        [\"Round 1\\n(Role-level)\", \"Round 2\\n(Service-level)\"], fontsize=12\n",
    "    )\n",
    "    ax.set_ylabel(\"Classification Agreement (%)\", fontsize=12)\n",
    "    ax.set_title(\n",
    "        \"Agreement Improvement: Round 1 → Round 2\\n(with 95% Confidence Intervals)\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.legend(title=\"Difficulty\", loc=\"lower right\")\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30f76c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_executive_summary(overall_df, category_df, difficulty_df, high_risk_df):\n",
    "    \"\"\"Generate executive summary statistics.\n",
    "\n",
    "    Args:\n",
    "      overall_df (pd.DataFrame): total simulation results matrix\n",
    "      category_df (pd.DataFrame): by-category simulation results matrix\n",
    "      difficulty_df (pd.DataFrame): by-difficulty simulation results matrix\n",
    "      high_risk_df (pd.DataFrame): high-risk simulation results matrix\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXECUTIVE SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    avg_miss = overall_df[\"miss_rate\"].mean()\n",
    "    worst_coder = overall_df.loc[overall_df[\"miss_rate\"].idxmax()]\n",
    "    best_coder = overall_df.loc[overall_df[\"miss_rate\"].idxmin()]\n",
    "\n",
    "    worst_category = category_df.loc[category_df[\"avg_miss_rate\"].idxmax()]\n",
    "    best_category = category_df.loc[category_df[\"avg_miss_rate\"].idxmin()]\n",
    "\n",
    "    worst_difficulty = difficulty_df.loc[difficulty_df[\"avg_miss_rate\"].idxmax()]\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "KEY METRICS:\n",
    "• Overall single-coder miss rate: {avg_miss:.1f}%\n",
    "• Best coder: {best_coder['coder']} ({best_coder['miss_rate']:.1f}% miss rate)\n",
    "• Worst coder: {worst_coder['coder']} ({worst_coder['miss_rate']:.1f}% miss rate)\n",
    "\n",
    "CATEGORY INSIGHTS:\n",
    "• Highest risk: {worst_category['category']} ({worst_category['avg_miss_rate']:.1f}% miss rate)\n",
    "• Lowest risk: {best_category['category']} ({best_category['avg_miss_rate']:.1f}% miss rate)\n",
    "\n",
    "DIFFICULTY INSIGHTS:\n",
    "• Highest risk difficulty: {worst_difficulty['difficulty']} ({worst_difficulty['avg_miss_rate']:.1f}% miss rate)\n",
    "\n",
    "HIGH-RISK COMBINATIONS (>20% miss rate):\"\"\"\n",
    "    )\n",
    "\n",
    "    for _, row in high_risk_df.head(5).iterrows():\n",
    "        print(f\"  • {row['category']} + {row['difficulty']}: {row['miss_rate']:.1f}%\")\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "RECOMMENDATIONS:\n",
    "1. Prioritize handbook updates for: {worst_category['category']}\n",
    "2. Consider dual-coding for: {worst_difficulty['difficulty']} contracts\n",
    "3. Targeted training for: {worst_coder['coder']} (highest miss rate)\n",
    "4. Low-risk categories ({best_category['category']}) suitable for single-coder production\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2c8f7",
   "metadata": {},
   "source": [
    "**ALL FUNCTION CALLS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d02fd6b",
   "metadata": {},
   "source": [
    "Data ingestion, cleanining, and EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bbf0fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service name normalization complete.\n",
      "  Unique services (raw): 143\n",
      "  Unique services (normalized): 122\n",
      "  Services merged: 21\n",
      "\n",
      "Data Preparation Validation:\n",
      "--------------------------------------------------\n",
      "  ✓ PASS: Service_Normalized column exists\n",
      "  ✓ PASS: No null Contract IDs\n",
      "  ✓ PASS: Normalization merged services (143 → 122)\n",
      "  ✓ PASS: All expected columns present\n",
      "--------------------------------------------------\n",
      "  All checks passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_FILE)\n",
    "df = clean_data(df)\n",
    "df = normalize_service_names(df, SERVICE_EQUIVALENCES)\n",
    "validate_preparation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f8abd",
   "metadata": {},
   "source": [
    "Descriptive analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4649d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coder Prefix Usage (% of each coder's assignments):\n",
      "------------------------------------------------------------\n",
      "prefix    23    92    56    54   22\n",
      "Coder                              \n",
      "D       34.3  28.7  18.5   4.6  5.6\n",
      "G       41.2  23.5  11.8   7.1  5.9\n",
      "W       30.3  30.3  11.8  11.8  5.3\n",
      "\n",
      "Identification Overlap by Round:\n",
      "------------------------------------------------------------\n",
      "Metric                              Round 1      Round 2\n",
      "------------------------------------------------------------\n",
      "All 3                                 16.0%        15.9%\n",
      "2 Coders                              32.8%        25.0%\n",
      "1 Coder                               51.3%        59.1%\n"
     ]
    }
   ],
   "source": [
    "pivot, top_prefixes = analyze_coder_profiles(df)\n",
    "overlap_summary = analyze_identification_overlap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09556871",
   "metadata": {},
   "source": [
    "Core Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5da4bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Agreement (Normalized Service Names, 95% CI):\n",
      "----------------------------------------------------------------------\n",
      "Segment            Agreement               95% CI        n\n",
      "----------------------------------------------------------------------\n",
      "Overall                59.5%       [48.6%, 71.6%]       74\n",
      "Round 1                48.2%       [33.9%, 60.7%]       56\n",
      "Round 2                94.4%      [83.3%, 100.0%]       18\n",
      "Easy                  100.0%     [100.0%, 100.0%]       11\n",
      "Medium                 35.3%       [11.8%, 53.1%]       17\n",
      "Hard                   58.7%       [43.5%, 73.9%]       46\n",
      "R1 Easy               100.0%     [100.0%, 100.0%]       10\n",
      "R1 Medium              35.3%       [17.6%, 58.8%]       17\n",
      "R1 Hard                37.9%       [20.7%, 55.2%]       29\n",
      "R2 Easy               100.0%     [100.0%, 100.0%]        1\n",
      "R2 Hard                94.1%      [82.4%, 100.0%]       17\n"
     ]
    }
   ],
   "source": [
    "results_df = compute_agreement_matrix(df)\n",
    "print_agreement_table(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ebff776",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_df = compute_pairwise_agreement(df)\n",
    "jaccard_df = compute_jaccard_similarity(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a177c41",
   "metadata": {},
   "source": [
    "Diagnostic Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Disagreement Taxonomy:\n",
      "------------------------------------------------------------\n",
      "Total disagreements: 30\n",
      "\n",
      "  Construction vs Admin (23/56)        14 ( 46.7%)\n",
      "  Granularity (same prefix)            11 ( 36.7%)\n",
      "  Professional vs Public Admin (54/92)   5 ( 16.7%)\n",
      "\n",
      "  Granularity (low impact): 11 (36.7%)\n",
      "  Substantive (addressable): 19 (63.3%)\n",
      "\n",
      "Top Confused Prefix Pairs:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m taxonomy_df = analyze_disagreement_taxonomy(df)\n\u001b[32m      2\u001b[39m confusion_counts = build_confusion_matrix(df)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mprint_confusion_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfusion_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m consistency_df = analyze_cross_contract_consistency(df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mprint_confusion_pairs\u001b[39m\u001b[34m(confusion_counts, top_n)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTop Confused Prefix Pairs:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m sorted_pairs = \u001b[38;5;28msorted\u001b[39m(\u001b[43mconfusion_counts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m(), key=\u001b[38;5;28;01mlambda\u001b[39;00m x: -x[\u001b[32m1\u001b[39m])[:top_n]\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (p1, p2), count \u001b[38;5;129;01min\u001b[39;00m sorted_pairs:\n\u001b[32m     24\u001b[39m     name1 = PREFIX_NAMES.get(p1, \u001b[33m\"\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "taxonomy_df = analyze_disagreement_taxonomy(df)\n",
    "confusion_matrix, confusion_counts = build_confusion_matrix(df)\n",
    "print_confusion_pairs(confusion_counts, 10)\n",
    "consistency_df = analyze_cross_contract_consistency(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc6fd5",
   "metadata": {},
   "source": [
    "Query Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = run_simulation(df)\n",
    "coder_cols = [c for c in sim_df.columns if c.endswith(\"_hit\") and c != \"union_hit\"]\n",
    "overall_df = analyze_overall(sim_df, coder_cols)\n",
    "category_df = analyze_by_category(sim_df, coder_cols)\n",
    "difficulty_df = analyze_by_difficulty(sim_df, coder_cols)\n",
    "cat_diff_df, cat_diff_pivot = analyze_category_by_difficulty(sim_df, coder_cols)\n",
    "coder_cat_df, coder_cat_pivot = analyze_coder_by_category(sim_df, coder_cols)\n",
    "contract_df = analyze_by_contract(sim_df, coder_cols)\n",
    "query_df = analyze_query_level(sim_df, coder_cols)\n",
    "category_risk_df, high_risk_df = compute_risk_scores(\n",
    "    sim_df, coder_cols, category_df, difficulty_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa46685",
   "metadata": {},
   "source": [
    "Executive Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ed7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_executive_summary(overall_df, category_df, difficulty_df, high_risk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70689ece",
   "metadata": {},
   "source": [
    "Agreement Figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb99a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agreement_comparison(results_df, f\"{OUTPUT_DIR}/fig_agreement_comparison.png\")\n",
    "plot_round_comparison_slope(results_df, f\"{OUTPUT_DIR}/fig_round_comparison_slope.png\")\n",
    "plot_coder_profiles(pivot, top_prefixes, f\"{OUTPUT_DIR}/fig_coder_profiles.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7c1bc",
   "metadata": {},
   "source": [
    "Query Simulation Figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category_miss_rates(category_df, f\"{OUTPUT_DIR}/fig_category_miss_rates.png\")\n",
    "plot_difficulty_miss_rates(difficulty_df, f\"{OUTPUT_DIR}/fig_difficulty_miss_rates.png\")\n",
    "plot_coder_category_heatmap(\n",
    "    coder_cat_pivot, f\"{OUTPUT_DIR}/fig_coder_category_heatmap.png\"\n",
    ")\n",
    "plot_difficulty_category_heatmap(\n",
    "    cat_diff_pivot, f\"{OUTPUT_DIR}/fig_difficulty_category_heatmap.png\"\n",
    ")\n",
    "plot_contract_heatmap(contract_df, coder_cols, f\"{OUTPUT_DIR}/fig_contract_heatmap.png\")\n",
    "plot_miss_rate_distribution(\n",
    "    sim_df, coder_cols, f\"{OUTPUT_DIR}/fig_miss_rate_distribution.png\"\n",
    ")\n",
    "plot_category_difficulty_grouped(\n",
    "    cat_diff_df, sim_df, coder_cols, f\"{OUTPUT_DIR}/fig_category_difficulty_grouped.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7e265",
   "metadata": {},
   "source": [
    "Miss Rate Heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_miss_rate_heatmap(contract_df, f\"{OUTPUT_DIR}/fig_miss_rate_heatmap.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "consistency_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
